name: Structural Variant Calling
description: Call structural variants with Severus, Wakhan, and CNVKit

agent_requirements: 
  cpu_cores: 32
  memory_gb: 64

parameters: 
  - name: tumor_sample_name
    label: Sample Name (tumor)
    type: string
    help: "The name of the tumor sample with BAMs and VCFs to be phased."

  - name: normal_sample_name
    label: Sample Name (normal)
    type: string
    optional: true
    help: "The name of the normal sample with VCFs to be phased (note that only a tumor BAM is phased). If not provided, the workflow will run in tumor-only mode."

  - name: input_folder
    label: Input Folder
    type: directory
    supports_location_mode: 'no_append'
    help: "The folder containing the input files."

  - name: output_folder
    label: Output Folder
    type: directory
    supports_location_mode: 'no_append'

  - name: cache_udocker_images
    label: Cache Udocker Image
    type: boolean
    value: true

steps: 
  - name: structural_variants
    type: cmd
    description: Call structural variants with Severus, Wakhan, and CNVKit
    args: 
      - |- # shell
        set -eu pipefail

        echo "*************************"
        echo "Starting Structural Variant Analysis Task"
        echo "Space on agent: $(df -h /scratch | tail -n 1 | awk '{print $4}')"
        echo "Input Parameters:"
        echo "  - tumor_sample_name: $tumor_sample_name"
        echo "  - normal_sample_name: $normal_sample_name"
        echo "  - input_folder: $input_folder"
        echo "  - output_folder: $output_folder"
        echo "  - cache_udocker_images: $cache_udocker_images"
        echo "*************************"

        # Function to copy files with progress bar, size reporting, and disk space monitoring
        copy_with_progress() {
            local dest_dir="$1"
            shift
            local files=("$@")
            local total_files=${#files[@]}
            local current_file=0
            local total_size_copied=0
            
            # Calculate total input size before copying
            local total_input_size=0
            for file in "${files[@]}"; do
                total_input_size=$((total_input_size + $(stat -c%s "$file" 2>/dev/null || echo "0")))
            done
            # Calculate GB using shell arithmetic (more reliable than bc)
            local total_input_gb=$((total_input_size / 1024 / 1024 / 1024))
            local total_input_mb=$((total_input_size / 1024 / 1024))
            local remainder_mb=$(((total_input_size % (1024 * 1024 * 1024)) / 1024 / 1024))
            
            echo "Copying $total_files files (${total_input_gb}.${remainder_mb} GB) to $dest_dir..."
            echo "================================================"
            
            for file in "${files[@]}"; do
                current_file=$((current_file + 1))
                local filename=$(basename "$file")
                local dest_path="$dest_dir/$filename"
                
                # Get file size using stat
                local file_size=$(stat -c%s "$file" 2>/dev/null || echo "0")
                local file_size_mb=$((file_size / 1024 / 1024))
                local file_size_kb=$(((file_size % (1024 * 1024)) / 1024))
                
                echo "[$current_file/$total_files] Copying: $filename (${file_size_mb}.${file_size_kb} MB)"
                
                # Copy with progress bar using pv
                if command -v pv >/dev/null 2>&1; then
                    pv "$file" > "$dest_path"
                else
                    # Fallback to cp if pv is not available
                    cp "$file" "$dest_path"
                fi
                
                # Verify copy and get actual copied size
                local copied_size=$(stat -c%s "$dest_path" 2>/dev/null || echo "0")
                local copied_size_mb=$((copied_size / 1024 / 1024))
                local copied_size_kb=$(((copied_size % (1024 * 1024)) / 1024))
                total_size_copied=$((total_size_copied + copied_size))
                
                echo "âœ“ Copied: $filename (${copied_size_mb}.${copied_size_kb} MB)"
                echo "----------------------------------------"
            done
            
            # Calculate total size in MB and GB using shell arithmetic
            local total_mb=$((total_size_copied / 1024 / 1024))
            local total_gb=$((total_size_copied / 1024 / 1024 / 1024))
            local remainder_mb=$(((total_size_copied % (1024 * 1024 * 1024)) / 1024 / 1024))
            
            echo "================================================"
            echo "âœ“ All files copied successfully!"
            echo "Total size copied: ${total_mb} MB (${total_gb}.${remainder_mb} GB)"
            
            # Show remaining disk space
            if command -v df >/dev/null 2>&1; then
                local dest_mount=$(df "$dest_dir" | tail -1 | awk '{print $1}')
                local available_space=$(df -h "$dest_dir" | tail -1 | awk '{print $4}')
                local used_percent=$(df "$dest_dir" | tail -1 | awk '{print $5}')
                echo "Remaining disk space on $dest_mount: $available_space ($used_percent used)"
            fi
            echo "================================================"
        }

        # Function to format file sizes using shell arithmetic (replaces bc usage)
        format_file_size() {
            local file_path="$1"
            local file_size=$(stat -c%s "$file_path" 2>/dev/null || echo "0")
            
            # Convert to appropriate unit
            if [ $file_size -ge 1073741824 ]; then
                # >= 1GB, show in GB
                local size_gb=$((file_size / 1024 / 1024 / 1024))
                local remainder_mb=$(((file_size % (1024 * 1024 * 1024)) / 1024 / 1024))
                local decimal_part=$((remainder_mb * 100 / 1024))
                echo "${size_gb}.${decimal_part} GB"
            elif [ $file_size -ge 1048576 ]; then
                # >= 1MB, show in MB
                local size_mb=$((file_size / 1024 / 1024))
                local remainder_kb=$(((file_size % (1024 * 1024)) / 1024))
                local decimal_part=$((remainder_kb * 100 / 1024))
                echo "${size_mb}.${decimal_part} MB"
            elif [ $file_size -ge 1024 ]; then
                # >= 1KB, show in KB
                local size_kb=$((file_size / 1024))
                local remainder_bytes=$((file_size % 1024))
                local decimal_part=$((remainder_bytes * 100 / 1024))
                echo "${size_kb}.${decimal_part} KB"
            else
                # < 1KB, show in bytes
                echo "${file_size} bytes"
            fi
        }

        # Set up udocker/miniwdl environment
        handle_miniwdl_failure() {
          local exit_code=$1
          echo "MiniWDL run failed with exit code $exit_code"
          echo "Capturing debug information..."
          bash "$TASK_DIR/utils/miniwdl-debug-capture.sh" /scratch/_LAST "$output_folder" "$TASK_NAME"
          exit $exit_code
        }
        export MINIWDL__SCHEDULER__CONTAINER_BACKEND=udocker
        export MINIWDL__FILE_IO__ALLOW_ANY_INPUT=true
        export MINIWDL__SCHEDULER__TASK_CONCURRENCY=8
        export UDOCKER_DIR=/scratch/.udocker

        # Set up resource path
        PB_RESOURCES_DIR="${WORKSPACE_DIR}/${RESOURCES_PATH}/hifisomatic_resources"

        # Gather inputs

        echo "*************************"
        echo "Gathering reference files..."
        echo "Space on agent: $(df -h /scratch | tail -n 1 | awk '{print $4}')"
        echo "*************************"
        
        # Reference files
        REF_FASTA="${PB_RESOURCES_DIR}/GCA_000001405.15_GRCh38_no_alt_analysis_set_maskedGRC_exclusions_v2.fasta"
        REF_INDEX="${PB_RESOURCES_DIR}/GCA_000001405.15_GRCh38_no_alt_analysis_set_maskedGRC_exclusions_v2.fasta.fai"
        REF_FLAT="${PB_RESOURCES_DIR}/refFlat.hg38.txt"

        # Verify reference files exist
        if [ ! -f "$REF_FASTA" ]; then
          echo "Error: Reference FASTA file not found at $REF_FASTA"
          echo "Please ensure the PacBio WDL resources have been downloaded using the Download PacBio Reference Data Resources task"
          exit 1
        fi
        
        if [ ! -f "$REF_INDEX" ]; then
          echo "Error: Reference FASTA index file not found at $REF_INDEX"
          echo "Please ensure the PacBio WDL resources have been downloaded using the Download PacBio Reference Data Resources task"
          exit 1
        fi
        
        if [ ! -f "$REF_FLAT" ]; then
          echo "Error: Reference FLAT file not found at $REF_FLAT"
          echo "Please ensure the PacBio WDL resources have been downloaded using the Download PacBio Reference Data Resources task"
          exit 1
        fi

        # Copy reference files to /scratch
        echo "Copying reference files to /scratch..."
        copy_with_progress "/scratch" "$REF_FASTA" "$REF_INDEX" "$REF_FLAT"

        # Set local file paths
        LOCAL_REF_FASTA="/scratch/$(basename "$REF_FASTA")"
        LOCAL_REF_INDEX="/scratch/$(basename "$REF_INDEX")"
        LOCAL_REF_FLAT="/scratch/$(basename "$REF_FLAT")"

        echo "*************************"
        echo "Gathering tumor and normal input files..."
        echo "Space on agent: $(df -h /scratch | tail -n 1 | awk '{print $4}')"
        echo "*************************"

        TUMOR_BAM="${input_folder}/${tumor_sample_name}.hiphase.bam"
        TUMOR_BAM_INDEX="${input_folder}/${tumor_sample_name}.hiphase.bam.bai"
        TUMOR_PHASED_VCF="${input_folder}/${tumor_sample_name}.clair3.small_variants.correct_ref.phased.vcf.gz"
        TUMOR_PHASED_VCF_INDEX="${TUMOR_PHASED_VCF}.tbi"
        TUMOR_SOMATIC_VCF="${input_folder}/${tumor_sample_name}_deepsomatic.phased.vcf.gz"
        TUMOR_SOMATIC_VCF_INDEX="${TUMOR_SOMATIC_VCF}.tbi"
        if [ -z "${normal_sample_name}" ]; then
          echo "Warning: Normal sample name not provided - running tumor-only analysis"
        else
          NORMAL_BAM="${input_folder}/${normal_sample_name}.hiphase.bam"
          NORMAL_BAM_INDEX="${input_folder}/${normal_sample_name}.hiphase.bam.bai"
          NORMAL_PHASED_VCF="${input_folder}/${normal_sample_name}.clair3.small_variants.correct_ref.phased.vcf.gz"
          NORMAL_PHASED_VCF_INDEX="${NORMAL_PHASED_VCF}.tbi"
        fi
        TRF_BED="${PB_RESOURCES_DIR}/human_GRCh38_no_alt_analysis_set.trf.bed"

        # Check inputs exist
        if [ ! -f "$TUMOR_BAM" ]; then
          echo "Error: Tumor BAM file not found at $TUMOR_BAM"
          exit 1
        fi
        if [ ! -f "$TUMOR_BAM_INDEX" ]; then
          echo "Error: Tumor BAM index file not found at $TUMOR_BAM_INDEX"
          exit 1
        fi
        if [ ! -f "$TUMOR_PHASED_VCF" ]; then
          echo "Error: Tumor phased VCF file not found at $TUMOR_PHASED_VCF"
          exit 1
        fi
        if [ ! -f "$TUMOR_PHASED_VCF_INDEX" ]; then
          echo "Error: Tumor phased VCF index file not found at $TUMOR_PHASED_VCF_INDEX"
          exit 1
        fi
        if [ ! -f "$TUMOR_SOMATIC_VCF" ]; then
          echo "Error: Tumor somatic VCF file not found at $TUMOR_SOMATIC_VCF"
          exit 1
        fi
        if [ ! -f "$TUMOR_SOMATIC_VCF_INDEX" ]; then
          echo "Error: Tumor somatic VCF index file not found at $TUMOR_SOMATIC_VCF_INDEX"
          exit 1
        fi
        if [ -z "${normal_sample_name}" ]; then
          echo "Warning: Normal sample name not provided - running tumor-only analysis"
        else
          if [ ! -f "$NORMAL_BAM" ]; then
            echo "Error: Normal BAM file not found at $NORMAL_BAM"
            exit 1
          fi
        fi
        if [ ! -f "$NORMAL_BAM_INDEX" ]; then
          echo "Error: Normal BAM index file not found at $NORMAL_BAM_INDEX"
          exit 1
        fi
        if [ ! -f "$NORMAL_PHASED_VCF" ]; then
          echo "Error: Normal phased VCF file not found at $NORMAL_PHASED_VCF"
          exit 1
        fi
        if [ ! -f "$NORMAL_PHASED_VCF_INDEX" ]; then
          echo "Error: Normal phased VCF index file not found at $NORMAL_PHASED_VCF_INDEX"
          exit 1
        fi
        if [ ! -f "$TRF_BED" ]; then
          echo "Error: TRF BED file not found at $TRF_BED"
          exit 1
        fi

        # Copy inputs to /scratch
        echo "Copying tumor and normal input files to /scratch..."
        copy_with_progress /scratch "$TUMOR_BAM" "$TUMOR_BAM_INDEX" "$TUMOR_PHASED_VCF" "$TUMOR_PHASED_VCF_INDEX" "$TRF_BED" "$TUMOR_SOMATIC_VCF" "$TUMOR_SOMATIC_VCF_INDEX"
        if [ -z "${normal_sample_name}" ]; then
          echo "Warning: Normal sample name not provided - running tumor-only analysis"
        else
          copy_with_progress /scratch "$NORMAL_BAM" "$NORMAL_BAM_INDEX" "$NORMAL_PHASED_VCF" "$NORMAL_PHASED_VCF_INDEX"
        fi

        # Set local file paths
        LOCAL_TUMOR_BAM="/scratch/$(basename "${TUMOR_BAM}")"
        LOCAL_TUMOR_BAM_INDEX="/scratch/$(basename "${TUMOR_BAM_INDEX}")"
        LOCAL_TUMOR_PHASED_VCF="/scratch/$(basename "${TUMOR_PHASED_VCF}")"
        LOCAL_TUMOR_PHASED_VCF_INDEX="/scratch/$(basename "${TUMOR_PHASED_VCF_INDEX}")"
        LOCAL_NORMAL_BAM="/scratch/$(basename "${NORMAL_BAM}")"
        LOCAL_NORMAL_BAM_INDEX="/scratch/$(basename "${NORMAL_BAM_INDEX}")"
        LOCAL_NORMAL_PHASED_VCF="/scratch/$(basename "${NORMAL_PHASED_VCF}")"
        LOCAL_NORMAL_PHASED_VCF_INDEX="/scratch/$(basename "${NORMAL_PHASED_VCF_INDEX}")"
        LOCAL_TRF_BED="/scratch/$(basename "${TRF_BED}")"
        LOCAL_TUMOR_SOMATIC_VCF="/scratch/$(basename "${TUMOR_SOMATIC_VCF}")"
        LOCAL_TUMOR_SOMATIC_VCF_INDEX="/scratch/$(basename "${TUMOR_SOMATIC_VCF_INDEX}")"

        echo "*************************"
        echo "Starting Severus analysis for $tumor_sample_name"
        echo "*************************"
        
        # Severus:
        # - Tumor BAM
        # - Tumor BAM Index
        # - Normal BAM
        # - Normal BAM Index
        # - Normal Phased VCF
        # - TRF BED
        # - PON TSV (note: this is optional in the WDL workflow, so ignoring it here)

        # Check if Severus outputs already exist in input folder
        SEVERUS_OUTPUT_VCF="${input_folder}/${tumor_sample_name}_severus/somatic_SVs/severus_somatic.vcf"
        SEVERUS_ALL_VCF="${input_folder}/${tumor_sample_name}_severus/all_SVs/severus_all.vcf"
        
        if [ -f "$SEVERUS_OUTPUT_VCF" ] && [ -f "$SEVERUS_ALL_VCF" ]; then
          echo "Severus outputs already exist, copying to /scratch and skipping Severus execution..."
          
          # Copy existing Severus outputs to /scratch
          cp -r "${input_folder}/${tumor_sample_name}_severus" "/scratch/"
          
          # Set the SEVERUS_OUTPUT variable to simulate successful completion
          SEVERUS_OUTPUT='{"outputs":{"Severus_sv.output_vcf":"/scratch/'${tumor_sample_name}'_severus/somatic_SVs/severus_somatic.vcf","Severus_sv.output_all_vcf":"/scratch/'${tumor_sample_name}'_severus/all_SVs/severus_all.vcf"}}'
          
          echo "Severus outputs copied successfully"
          echo "Severus output: $SEVERUS_OUTPUT"
        else
          echo "Severus outputs not found, running Severus..."
          
          # Pre-execution logging for Severus
          echo "================================================"
          echo "ðŸš€ STARTING SEVERUS ANALYSIS"
          echo "================================================"
          echo "ðŸ“… Server Time: $(date)"
          echo "ðŸ“ Input Files:"
          echo "  - Tumor BAM: $(basename "$LOCAL_TUMOR_BAM") ($(format_file_size "$LOCAL_TUMOR_BAM" "GB") GB)"
          echo "  - Tumor BAM Index: $(basename "$LOCAL_TUMOR_BAM_INDEX") ($(format_file_size "$LOCAL_TUMOR_BAM_INDEX" "MB") MB)"
          echo "  - Normal BAM: $(basename "$LOCAL_NORMAL_BAM") ($(format_file_size "$LOCAL_NORMAL_BAM" "GB") GB)"
          echo "  - Normal BAM Index: $(basename "$LOCAL_NORMAL_BAM_INDEX") ($(format_file_size "$LOCAL_NORMAL_BAM_INDEX" "MB") MB)"
          echo "  - Normal Phased VCF: $(basename "$LOCAL_NORMAL_PHASED_VCF") ($(format_file_size "$LOCAL_NORMAL_PHASED_VCF" "MB") MB)"
          echo "  - TRF BED: $(basename "$LOCAL_TRF_BED") ($(format_file_size "$LOCAL_TRF_BED" "MB") MB)"
          echo "âš™ï¸  Configuration:"
          echo "  - Threads: $AGENT_CPU_CORES"
          echo "  - Min Support Reads: 3"
          echo "================================================"
          
          # Record start time
          SEVERUS_START_TIME=$(date +%s)
          
          # Run Severus
          echo "Running Severus..."
          jq -n \
            --arg pname "$tumor_sample_name" \
            --arg bam "$LOCAL_TUMOR_BAM" \
            --arg bam_index "$LOCAL_TUMOR_BAM_INDEX" \
            --arg normal_bam "$LOCAL_NORMAL_BAM" \
            --arg normal_bam_index "$LOCAL_NORMAL_BAM_INDEX" \
            --arg phased_vcf "$LOCAL_NORMAL_PHASED_VCF" \
            --arg trf_bed "$LOCAL_TRF_BED" \
            --argjson threads "$AGENT_CPU_CORES" \
            --argjson min_supp_reads 3 \
            '{
              "Severus_sv.pname": $pname,
              "Severus_sv.tumor_bam": $bam,
              "Severus_sv.tumor_bam_index": $bam_index,
              "Severus_sv.normal_bam": $normal_bam,
              "Severus_sv.normal_bam_index": $normal_bam_index,
              "Severus_sv.phased_vcf": $phased_vcf,
              "Severus_sv.trf_bed": $trf_bed,
              "Severus_sv.threads": $threads,
              "Severus_sv.min_supp_reads": $min_supp_reads
            }' > /scratch/severus_inputs.json

          set +e
          SEVERUS_OUTPUT=$(miniwdl run \
            "${TASK_DIR}/HiFi-somatic-WDL-0.9.2/tasks/structural_variants_updated.wdl" \
            --task Severus_sv \
            --dir /scratch \
            --runtime-cpu-max=$AGENT_CPU_CORES \
            --runtime-memory-max=${AGENT_MEMORY_GB}G \
            --no-cache \
            -i /scratch/severus_inputs.json 2>/dev/null)
          SEVERUS_OUTPUT_EXIT_CODE=$?
          if [ $SEVERUS_OUTPUT_EXIT_CODE -ne 0 ]; then
            handle_miniwdl_failure $SEVERUS_OUTPUT_EXIT_CODE
          fi
          
          # Post-execution logging for Severus
          SEVERUS_END_TIME=$(date +%s)
          SEVERUS_DURATION=$((SEVERUS_END_TIME - SEVERUS_START_TIME))
          SEVERUS_DURATION_HOUR=$((SEVERUS_DURATION / 3600))
          SEVERUS_DURATION_MIN=$(((SEVERUS_DURATION % 3600) / 60))
          SEVERUS_DURATION_SEC=$((SEVERUS_DURATION % 60))
          
          echo "================================================"
          echo "âœ… SEVERUS ANALYSIS COMPLETED SUCCESSFULLY"
          echo "================================================"
          echo "â±ï¸  Execution Time: ${SEVERUS_DURATION_HOUR}h ${SEVERUS_DURATION_MIN}m ${SEVERUS_DURATION_SEC}s"
          
          # Extract output file paths from SEVERUS_OUTPUT
          SEVERUS_SOMATIC_VCF=$(echo "$SEVERUS_OUTPUT" | jq -r '.outputs."Severus_sv.output_vcf"')
          SEVERUS_ALL_VCF=$(echo "$SEVERUS_OUTPUT" | jq -r '.outputs."Severus_sv.output_all_vcf"')
          
          # Calculate total output size
          SEVERUS_TOTAL_SIZE=0
          if [ -f "$SEVERUS_SOMATIC_VCF" ]; then
            SEVERUS_TOTAL_SIZE=$((SEVERUS_TOTAL_SIZE + $(stat -c%s "$SEVERUS_SOMATIC_VCF" 2>/dev/null || echo "0")))
          fi
          if [ -f "$SEVERUS_ALL_VCF" ]; then
            SEVERUS_TOTAL_SIZE=$((SEVERUS_TOTAL_SIZE + $(stat -c%s "$SEVERUS_ALL_VCF" 2>/dev/null || echo "0")))
          fi
          
          # Format total size
          if [ $SEVERUS_TOTAL_SIZE -ge 1073741824 ]; then
            SEVERUS_TOTAL_GB=$((SEVERUS_TOTAL_SIZE / 1024 / 1024 / 1024))
            SEVERUS_TOTAL_MB=$(((SEVERUS_TOTAL_SIZE % (1024 * 1024 * 1024)) / 1024 / 1024))
            SEVERUS_TOTAL_DECIMAL=$((SEVERUS_TOTAL_MB * 100 / 1024))
            SEVERUS_TOTAL_FORMATTED="${SEVERUS_TOTAL_GB}.${SEVERUS_TOTAL_DECIMAL} GB"
          elif [ $SEVERUS_TOTAL_SIZE -ge 1048576 ]; then
            SEVERUS_TOTAL_MB=$((SEVERUS_TOTAL_SIZE / 1024 / 1024))
            SEVERUS_TOTAL_KB=$(((SEVERUS_TOTAL_SIZE % (1024 * 1024)) / 1024))
            SEVERUS_TOTAL_DECIMAL=$((SEVERUS_TOTAL_KB * 100 / 1024))
            SEVERUS_TOTAL_FORMATTED="${SEVERUS_TOTAL_MB}.${SEVERUS_TOTAL_DECIMAL} MB"
          else
            SEVERUS_TOTAL_FORMATTED="${SEVERUS_TOTAL_SIZE} bytes"
          fi
          
          echo "ðŸ“ **Total Output Size: $SEVERUS_TOTAL_FORMATTED**"
          echo "ðŸ’¾ **Remaining Disk Space: $(df -h /scratch | tail -n 1 | awk '{print $4}')**"
          echo "ðŸ“ Output Files:"
          
          if [ -f "$SEVERUS_SOMATIC_VCF" ]; then
            echo "  - Somatic SV VCF: $(basename "$SEVERUS_SOMATIC_VCF") ($(format_file_size "$SEVERUS_SOMATIC_VCF"))"
          fi
          if [ -f "$SEVERUS_ALL_VCF" ]; then
            echo "  - All SV VCF: $(basename "$SEVERUS_ALL_VCF") ($(format_file_size "$SEVERUS_ALL_VCF"))"
          fi
          echo "================================================"
          
        fi
      
        # Wakhan:
        # - Tumor BAM
        # - Tumor BAM index 
        # - Reference FASTA
        # - Reference FASTA index
        # - Severus SV VCF
        # - Normal Phased VCF
        # - Tumor Phased VCF

        # Get Severus SV VCF from Severus step output
        echo "Attempting to extract Severus SV VCF from output..."
        SEVERUS_SV_VCF=$(echo "$SEVERUS_OUTPUT" | jq -r '.outputs."Severus_sv.output_vcf"')
        echo "Extracted SEVERUS_SV_VCF: '$SEVERUS_SV_VCF'"
        
        if [ -z "$SEVERUS_SV_VCF" ] || [ "$SEVERUS_SV_VCF" = "null" ]; then
          echo "Error: Severus SV VCF not found in Severus step output"
          echo "DEBUG: Full SEVERUS_OUTPUT content:"
          echo "$SEVERUS_OUTPUT"
          echo "DEBUG: jq command used: echo \"\$SEVERUS_OUTPUT\" | jq -r '.outputs.\"Severus_sv.output_vcf\"'"
          exit 1
        fi

        # Copy Severus VCF to scratch
        LOCAL_SEVERUS_SV_VCF="/scratch/$(basename "$SEVERUS_SV_VCF")"
        cp "$SEVERUS_SV_VCF" "$LOCAL_SEVERUS_SV_VCF"

        # Pre-execution logging for Wakhan
        echo "================================================"
        echo "ðŸš€ STARTING WAKHAN ANALYSIS"
        echo "================================================"
        echo "ðŸ“… Server Time: $(date)"
        echo "ðŸ“ Input Files:"
        echo "  - Tumor BAM: $(basename "$LOCAL_TUMOR_BAM") ($(format_file_size "$LOCAL_TUMOR_BAM" "GB") GB)"
        echo "  - Tumor BAM Index: $(basename "$LOCAL_TUMOR_BAM_INDEX") ($(format_file_size "$LOCAL_TUMOR_BAM_INDEX" "MB") MB)"
        echo "  - Reference FASTA: $(basename "$LOCAL_REF_FASTA") ($(format_file_size "$LOCAL_REF_FASTA" "GB") GB)"
        echo "  - Reference FASTA Index: $(basename "$LOCAL_REF_INDEX") ($(format_file_size "$LOCAL_REF_INDEX" "MB") MB)"
        echo "  - Severus SV VCF: $(basename "$LOCAL_SEVERUS_SV_VCF") ($(format_file_size "$LOCAL_SEVERUS_SV_VCF" "MB") MB)"
        echo "  - Normal Phased VCF: $(basename "$LOCAL_NORMAL_PHASED_VCF") ($(format_file_size "$LOCAL_NORMAL_PHASED_VCF" "MB") MB)"
        echo "  - Tumor Phased VCF: $(basename "$LOCAL_TUMOR_PHASED_VCF") ($(format_file_size "$LOCAL_TUMOR_PHASED_VCF" "MB") MB)"
        echo "================================================"
        
        # Record start time
        WAKHAN_START_TIME=$(date +%s)

        # Download and install Wakhan directly from GitHub
        echo "Downloading and installing Wakhan..."
        set +e
        
        # Add local bin directory to PATH for pip-installed packages
        export PATH="$HOME/.local/bin:$PATH"
        
        # Check if Wakhan is already installed
        if command -v wakhan >/dev/null 2>&1; then
          echo "Wakhan is already installed, skipping installation..."
        else
          echo "Installing Wakhan dependencies and package..."
          
          # Install dependencies if not already available (suppress PATH warnings)
          pip install -q --no-warn-script-location setuptools pysam pyfaidx numpy pandas plotly scikit-learn scipy ruptures vcf_parser kaleido intervaltree > /dev/null 2>&1 || {
            echo "Failed to install Wakhan dependencies"
            exit 1
          }
          
          # Download and install Wakhan from GitHub
          cd /scratch
          if [ ! -d "Wakhan" ]; then
            git clone https://github.com/KolmogorovLab/Wakhan.git > /dev/null 2>&1 || {
              echo "Failed to clone Wakhan repository"
              exit 1
            }
          fi
          
          cd Wakhan
          pip install -q --no-warn-script-location -e . > /dev/null 2>&1 || {
            echo "Failed to install Wakhan package"
            exit 1
          }
          
          # Verify Wakhan is installed and accessible
          if command -v wakhan -h >/dev/null 2>&1; then
            echo "Wakhan installation successful"
          else
            echo "Wakhan installation verification failed - command not found in PATH"
            echo "PATH is: $PATH"
            echo "Checking for wakhan binary in common locations..."
            find "$HOME/.local/bin" -name "wakhan*" -type f 2>/dev/null || echo "No wakhan binary found in ~/.local/bin"
            exit 1
          fi
          
          cd /scratch
        fi
        
        cd /scratch
        
        # Build Wakhan command arguments
        WAKHAN_ARGS="--threads $AGENT_CPU_CORES --target-bam $LOCAL_TUMOR_BAM --reference $LOCAL_REF_FASTA --genome-name $tumor_sample_name --out-dir $tumor_sample_name""_wakhan --breakpoints $LOCAL_SEVERUS_SV_VCF --loh-enable --ploidy-range 1-6 --purity-range 0.2-1.0"
        
        # Add centromere annotation file (from installed Wakhan)
        CENTROMERE_BED="${WORKSPACE_DIR}/${RESOURCES_PATH}/hifisomatic_resources/human_GRCh38_no_alt_analysis_set.centromere.bed"
        if [ -f "$CENTROMERE_BED" ]; then
          cp "$CENTROMERE_BED" "/scratch/grch38.centromere.bed"
          WAKHAN_ARGS="$WAKHAN_ARGS --centromere /scratch/grch38.centromere.bed"
        else
          # Use Wakhan's built-in centromere file
          WAKHAN_ARGS="$WAKHAN_ARGS --centromere /scratch/Wakhan/src/annotations/grch38.cen_coord.curated.bed"
        fi
        
        # Add normal germline VCF if available, otherwise use tumor VCF with hets ratio
        if [ -n "${normal_sample_name}" ]; then
          WAKHAN_ARGS="$WAKHAN_ARGS --normal-phased-vcf $LOCAL_NORMAL_PHASED_VCF"
        else
          WAKHAN_ARGS="$WAKHAN_ARGS --tumor-vcf $LOCAL_TUMOR_PHASED_VCF --hets-ratio 0.25"
        fi

        # Run Wakhan directly
        echo "Running Wakhan with args: $WAKHAN_ARGS"
        wakhan $WAKHAN_ARGS > /dev/null 2>/dev/null
        
        WAKHAN_OUTPUT_EXIT_CODE=$?
        set -e
        
        if [ $WAKHAN_OUTPUT_EXIT_CODE -ne 0 ]; then
          echo "Wakhan failed with exit code $WAKHAN_OUTPUT_EXIT_CODE"
          exit $WAKHAN_OUTPUT_EXIT_CODE
        fi

        # Process Wakhan outputs (same logic as in WDL)
        echo "Processing Wakhan outputs..."
        
        # Save purity and ploidy
        cd ${tumor_sample_name}_wakhan
        # Create TSV file with headers
        echo -e "folder_name\tploidy\tpurity\tconfidence" > folder_numbers.tsv

        # Find directories matching the pattern and process them
        find . -type d -regex ".*/[0-9.]+_[0-9.]+_[0-9.]+$" | while read dir; do
            # Get just the folder name without the path
            folder_name=$(basename "$dir")
            
            # Split the folder name into components
            ploidy=$(echo $folder_name | cut -d'_' -f1)
            purity=$(echo $folder_name | cut -d'_' -f2)
            confidence=$(echo $folder_name | cut -d'_' -f3)
            
            # Append to a temporary file
            echo -e "$folder_name\t$ploidy\t$purity\t$confidence"
        done | sort -t$'\t' -k4,4rn > temp.tsv

        # Combine header and sorted content
        (head -n 1 folder_numbers.tsv; cat temp.tsv) > ../purity_ploidy.tsv
        rm temp.tsv folder_numbers.tsv

        cd ..

        # Compress all output
        tar -czvf ${tumor_sample_name}_wakhan.tar.gz ${tumor_sample_name}_wakhan

        # Keep the bed output of the best solution
        best_folder=$(head -n 2 purity_ploidy.tsv | tail -n 1 | cut -f1)
        echo "Best folder: $best_folder"
        cp -r ${tumor_sample_name}_wakhan/${best_folder} ${tumor_sample_name}_wakhan_best
        # Delete variation_plots folder (big!)
        rm -rf ${tumor_sample_name}_wakhan_best/variation_plots
        
        # Copy and rename files with proper error handling
        echo "Processing bed output files..."
        
        # Handle copynumbers_segments files (there may be multiple HP files)
        if ls ${tumor_sample_name}_wakhan_best/bed_output/*copynumbers_segments*.bed 1> /dev/null 2>&1; then
          # If there are multiple files, combine them or take the first one
          copynumbers_files=($(ls ${tumor_sample_name}_wakhan_best/bed_output/*copynumbers_segments*.bed))
          if [ ${#copynumbers_files[@]} -eq 1 ]; then
            # Single file - just rename it
            mv "${copynumbers_files[0]}" "${tumor_sample_name}.copynumbers_segments.bed"
          else
            # Multiple files - combine them or take the first one
            echo "Found ${#copynumbers_files[@]} copynumbers files, using the first one"
            cp "${copynumbers_files[0]}" "${tumor_sample_name}.copynumbers_segments.bed"
          fi
        else
          echo "Warning: No copynumbers_segments files found"
        fi
        
        # Handle loh_regions file
        if [ -f "${tumor_sample_name}_wakhan_best/bed_output/loh_regions.bed" ]; then
          mv "${tumor_sample_name}_wakhan_best/bed_output/loh_regions.bed" "${tumor_sample_name}.loh_regions.bed"
        else
          echo "Warning: loh_regions.bed not found"
        fi
        
        # Handle cancer genes file (check both possible names)
        if [ -f "${tumor_sample_name}_wakhan_best/bed_output/cancer_genes_copynumber_states.bed" ]; then
          mv "${tumor_sample_name}_wakhan_best/bed_output/cancer_genes_copynumber_states.bed" "${tumor_sample_name}.cancer_genes_copynumber.bed"
        elif [ -f "${tumor_sample_name}_wakhan_best/bed_output/genes_copynumber_states.bed" ]; then
          mv "${tumor_sample_name}_wakhan_best/bed_output/genes_copynumber_states.bed" "${tumor_sample_name}.cancer_genes_copynumber.bed"
        else
          echo "Warning: cancer genes copynumber file not found"
        fi

        rm -rf ${tumor_sample_name}_wakhan

        # Post-execution logging for Wakhan
        WAKHAN_END_TIME=$(date +%s)
        WAKHAN_DURATION=$((WAKHAN_END_TIME - WAKHAN_START_TIME))
        WAKHAN_DURATION_HOUR=$((WAKHAN_DURATION / 3600))
        WAKHAN_DURATION_MIN=$(((WAKHAN_DURATION % 3600) / 60))
        WAKHAN_DURATION_SEC=$((WAKHAN_DURATION % 60))
        
        echo "================================================"
        echo "âœ… WAKHAN ANALYSIS COMPLETED SUCCESSFULLY"
        echo "================================================"
        echo "â±ï¸  Execution Time: ${WAKHAN_DURATION_HOUR}h ${WAKHAN_DURATION_MIN}m ${WAKHAN_DURATION_SEC}s"
        
        # Calculate total output size
        WAKHAN_TOTAL_SIZE=0
        if [ -f "${tumor_sample_name}_wakhan.tar.gz" ]; then
          WAKHAN_TOTAL_SIZE=$((WAKHAN_TOTAL_SIZE + $(stat -c%s "${tumor_sample_name}_wakhan.tar.gz" 2>/dev/null || echo "0")))
        fi
        if [ -f "purity_ploidy.tsv" ]; then
          WAKHAN_TOTAL_SIZE=$((WAKHAN_TOTAL_SIZE + $(stat -c%s "purity_ploidy.tsv" 2>/dev/null || echo "0")))
        fi
        if [ -f "${tumor_sample_name}.copynumbers_segments.bed" ]; then
          WAKHAN_TOTAL_SIZE=$((WAKHAN_TOTAL_SIZE + $(stat -c%s "${tumor_sample_name}.copynumbers_segments.bed" 2>/dev/null || echo "0")))
        fi
        if [ -f "${tumor_sample_name}.loh_regions.bed" ]; then
          WAKHAN_TOTAL_SIZE=$((WAKHAN_TOTAL_SIZE + $(stat -c%s "${tumor_sample_name}.loh_regions.bed" 2>/dev/null || echo "0")))
        fi
        if [ -f "${tumor_sample_name}.cancer_genes_copynumber.bed" ]; then
          WAKHAN_TOTAL_SIZE=$((WAKHAN_TOTAL_SIZE + $(stat -c%s "${tumor_sample_name}.cancer_genes_copynumber.bed" 2>/dev/null || echo "0")))
        fi
        
        # Format total size
        if [ $WAKHAN_TOTAL_SIZE -ge 1073741824 ]; then
          WAKHAN_TOTAL_GB=$((WAKHAN_TOTAL_SIZE / 1024 / 1024 / 1024))
          WAKHAN_TOTAL_MB=$(((WAKHAN_TOTAL_SIZE % (1024 * 1024 * 1024)) / 1024 / 1024))
          WAKHAN_TOTAL_DECIMAL=$((WAKHAN_TOTAL_MB * 100 / 1024))
          WAKHAN_TOTAL_FORMATTED="${WAKHAN_TOTAL_GB}.${WAKHAN_TOTAL_DECIMAL} GB"
        elif [ $WAKHAN_TOTAL_SIZE -ge 1048576 ]; then
          WAKHAN_TOTAL_MB=$((WAKHAN_TOTAL_SIZE / 1024 / 1024))
          WAKHAN_TOTAL_KB=$(((WAKHAN_TOTAL_SIZE % (1024 * 1024)) / 1024))
          WAKHAN_TOTAL_DECIMAL=$((WAKHAN_TOTAL_KB * 100 / 1024))
          WAKHAN_TOTAL_FORMATTED="${WAKHAN_TOTAL_MB}.${WAKHAN_TOTAL_DECIMAL} MB"
        else
          WAKHAN_TOTAL_FORMATTED="${WAKHAN_TOTAL_SIZE} bytes"
        fi
        
        echo "ðŸ“ **Total Output Size: $WAKHAN_TOTAL_FORMATTED**"
        echo "ðŸ’¾ **Remaining Disk Space: $(df -h /scratch | tail -n 1 | awk '{print $4}')**"
        echo "ðŸ“ Output Files:"
        
        # Check for Wakhan output files and report their sizes
        if [ -f "${tumor_sample_name}_wakhan.tar.gz" ]; then
          echo "  - Wakhan Archive: ${tumor_sample_name}_wakhan.tar.gz ($(format_file_size "${tumor_sample_name}_wakhan.tar.gz"))"
        fi
        if [ -f "purity_ploidy.tsv" ]; then
          echo "  - Purity Ploidy: purity_ploidy.tsv ($(format_file_size "purity_ploidy.tsv"))"
        fi
        if [ -f "${tumor_sample_name}.copynumbers_segments.bed" ]; then
          echo "  - Copy Number Segments: ${tumor_sample_name}.copynumbers_segments.bed ($(format_file_size "${tumor_sample_name}.copynumbers_segments.bed"))"
        fi
        if [ -f "${tumor_sample_name}.loh_regions.bed" ]; then
          echo "  - LOH Regions: ${tumor_sample_name}.loh_regions.bed ($(format_file_size "${tumor_sample_name}.loh_regions.bed"))"
        fi
        if [ -f "${tumor_sample_name}.cancer_genes_copynumber.bed" ]; then
          echo "  - Cancer Genes Copy Number: ${tumor_sample_name}.cancer_genes_copynumber.bed ($(format_file_size "${tumor_sample_name}.cancer_genes_copynumber.bed"))"
        fi
        echo "================================================"
       
        # Chord HRD:
        # - DeepSomatic VCF
        # - Severus SV VCF

        # Pre-execution logging for Chord HRD
        echo "================================================"
        echo "ðŸš€ STARTING CHORD HRD ANALYSIS"
        echo "================================================"
        echo "ðŸ“… Server Time: $(date)"
        echo "ðŸ“ Input Files:"
        echo "  - DeepSomatic VCF: $(basename "$LOCAL_TUMOR_SOMATIC_VCF") ($(format_file_size "$LOCAL_TUMOR_SOMATIC_VCF" "MB") MB)"
        echo "  - Severus SV VCF: $(basename "$SEVERUS_SV_VCF") ($(format_file_size "$SEVERUS_SV_VCF" "MB") MB)"
        echo "================================================"
        
        # Record start time
        CHORD_START_TIME=$(date +%s)

        # Generate Chord HRD input JSON
        jq -n \
          --arg pname "$tumor_sample_name" \
          --arg deepsomatic_vcf "$LOCAL_TUMOR_SOMATIC_VCF" \
          --arg severus_sv_vcf "$SEVERUS_SV_VCF" \
          '{
            "chord_hrd.pname": $pname,
            "chord_hrd.small_variant_vcf": $deepsomatic_vcf,
            "chord_hrd.sv_vcf": $severus_sv_vcf
          }' > /scratch/chord_hrd_inputs.json

        # Run Chord HRD
        echo "Running Chord HRD..."
        set +e
        CHORD_HRD_OUTPUT=$(miniwdl run \
          "${TASK_DIR}/HiFi-somatic-WDL-0.9.2/tasks/annotation.wdl" \
          --task chord_hrd \
          --dir /scratch \
          --runtime-cpu-max=$AGENT_CPU_CORES \
          --runtime-memory-max=${AGENT_MEMORY_GB}G \
          --no-cache \
          -i /scratch/chord_hrd_inputs.json 2>/dev/null)
        CHORD_HRD_OUTPUT_EXIT_CODE=$?
        if [ $CHORD_HRD_OUTPUT_EXIT_CODE -ne 0 ]; then
          handle_miniwdl_failure $CHORD_HRD_OUTPUT_EXIT_CODE
        fi
        
        # Post-execution logging for Chord HRD
        CHORD_END_TIME=$(date +%s)
        CHORD_DURATION=$((CHORD_END_TIME - CHORD_START_TIME))
        CHORD_DURATION_HOUR=$((CHORD_DURATION / 3600))
        CHORD_DURATION_MIN=$(((CHORD_DURATION % 3600) / 60))
        CHORD_DURATION_SEC=$((CHORD_DURATION % 60))
        
        echo "================================================"
        echo "âœ… CHORD HRD ANALYSIS COMPLETED SUCCESSFULLY"
        echo "================================================"
        echo "â±ï¸  Execution Time: ${CHORD_DURATION_HOUR}h ${CHORD_DURATION_MIN}m ${CHORD_DURATION_SEC}s"
        
        # Extract output file paths from CHORD_HRD_OUTPUT
        CHORD_HRD_LOG=$(echo "$CHORD_HRD_OUTPUT" | jq -r '.outputs."chord_hrd.chord_log"')
        CHORD_HRD_PREDICTION=$(echo "$CHORD_HRD_OUTPUT" | jq -r '.outputs."chord_hrd.chord_prediction"')
        CHORD_HRD_SIGNATURE=$(echo "$CHORD_HRD_OUTPUT" | jq -r '.outputs."chord_hrd.chord_signature"')
        
        # Calculate total output size
        CHORD_TOTAL_SIZE=0
        if [ -f "$CHORD_HRD_LOG" ]; then
          CHORD_TOTAL_SIZE=$((CHORD_TOTAL_SIZE + $(stat -c%s "$CHORD_HRD_LOG" 2>/dev/null || echo "0")))
        fi
        if [ -f "$CHORD_HRD_PREDICTION" ]; then
          CHORD_TOTAL_SIZE=$((CHORD_TOTAL_SIZE + $(stat -c%s "$CHORD_HRD_PREDICTION" 2>/dev/null || echo "0")))
        fi
        if [ -f "$CHORD_HRD_SIGNATURE" ]; then
          CHORD_TOTAL_SIZE=$((CHORD_TOTAL_SIZE + $(stat -c%s "$CHORD_HRD_SIGNATURE" 2>/dev/null || echo "0")))
        fi
        
        # Format total size
        if [ $CHORD_TOTAL_SIZE -ge 1073741824 ]; then
          CHORD_TOTAL_GB=$((CHORD_TOTAL_SIZE / 1024 / 1024 / 1024))
          CHORD_TOTAL_MB=$(((CHORD_TOTAL_SIZE % (1024 * 1024 * 1024)) / 1024 / 1024))
          CHORD_TOTAL_DECIMAL=$((CHORD_TOTAL_MB * 100 / 1024))
          CHORD_TOTAL_FORMATTED="${CHORD_TOTAL_GB}.${CHORD_TOTAL_DECIMAL} GB"
        elif [ $CHORD_TOTAL_SIZE -ge 1048576 ]; then
          CHORD_TOTAL_MB=$((CHORD_TOTAL_SIZE / 1024 / 1024))
          CHORD_TOTAL_KB=$(((CHORD_TOTAL_SIZE % (1024 * 1024)) / 1024))
          CHORD_TOTAL_DECIMAL=$((CHORD_TOTAL_KB * 100 / 1024))
          CHORD_TOTAL_FORMATTED="${CHORD_TOTAL_MB}.${CHORD_TOTAL_DECIMAL} MB"
        else
          CHORD_TOTAL_FORMATTED="${CHORD_TOTAL_SIZE} bytes"
        fi
        
        echo "ðŸ“ **Total Output Size: $CHORD_TOTAL_FORMATTED**"
        echo "ðŸ’¾ **Remaining Disk Space: $(df -h /scratch | tail -n 1 | awk '{print $4}')**"
        echo "ðŸ“ Output Files:"
        
        if [ -f "$CHORD_HRD_LOG" ]; then
          echo "  - HRD Log: $(basename "$CHORD_HRD_LOG") ($(format_file_size "$CHORD_HRD_LOG"))"
        fi
        if [ -f "$CHORD_HRD_PREDICTION" ]; then
          echo "  - HRD Prediction: $(basename "$CHORD_HRD_PREDICTION") ($(format_file_size "$CHORD_HRD_PREDICTION"))"
        fi
        if [ -f "$CHORD_HRD_SIGNATURE" ]; then
          echo "  - HRD Signature: $(basename "$CHORD_HRD_SIGNATURE") ($(format_file_size "$CHORD_HRD_SIGNATURE"))"
        fi
        echo "================================================"
        
        echo "Chord HRD output: $CHORD_HRD_OUTPUT"
        echo "Chord HRD completed successfully"

        # CNVKit:
        # - Tumor BAM
        # - Tumor BAM index
        # - Normal BAM
        # - Normal BAM index
        # - Reference FASTA
        # - Reference FASTA index
        # - Reference FLAT

        # Pre-execution logging for CNVKit
        echo "================================================"
        echo "ðŸš€ STARTING CNVKIT ANALYSIS"
        echo "================================================"
        echo "ðŸ“… Server Time: $(date)"
        echo "ðŸ“ Input Files:"
        echo "  - Tumor BAM: $(basename "$LOCAL_TUMOR_BAM") ($(format_file_size "$LOCAL_TUMOR_BAM" "GB") GB)"
        echo "  - Tumor BAM Index: $(basename "$LOCAL_TUMOR_BAM_INDEX") ($(format_file_size "$LOCAL_TUMOR_BAM_INDEX" "MB") MB)"
        echo "  - Normal BAM: $(basename "$LOCAL_NORMAL_BAM") ($(format_file_size "$LOCAL_NORMAL_BAM" "GB") GB)"
        echo "  - Normal BAM Index: $(basename "$LOCAL_NORMAL_BAM_INDEX") ($(format_file_size "$LOCAL_NORMAL_BAM_INDEX" "MB") MB)"
        echo "  - Reference FASTA: $(basename "$LOCAL_REF_FASTA") ($(format_file_size "$LOCAL_REF_FASTA" "GB") GB)"
        echo "  - Reference FASTA Index: $(basename "$LOCAL_REF_INDEX") ($(format_file_size "$LOCAL_REF_INDEX" "MB") MB)"
        echo "  - Reference FLAT: $(basename "$LOCAL_REF_FLAT") ($(format_file_size "$LOCAL_REF_FLAT" "GB") GB)"
        echo "================================================"
        
        # Record start time
        CNVKIT_START_TIME=$(date +%s)

        echo "Starting CNVKit..."

        # Generate CNVKit input JSON
        jq -n \
          --arg pname "$tumor_sample_name" \
          --arg tumor_bam "$LOCAL_TUMOR_BAM" \
          --arg tumor_bam_index "$LOCAL_TUMOR_BAM_INDEX" \
          --arg normal_bam "$LOCAL_NORMAL_BAM" \
          --arg normal_bam_index "$LOCAL_NORMAL_BAM_INDEX" \
          --arg ref_fasta "$LOCAL_REF_FASTA" \
          --arg ref_fasta_index "$LOCAL_REF_INDEX" \
          --arg refFlat "$LOCAL_REF_FLAT" \
          --argjson threads "$AGENT_CPU_CORES" \
          '{
            "cnvkit_tumor.pname": $pname,
            "cnvkit_tumor.tumor_bam": $tumor_bam,
            "cnvkit_tumor.tumor_bam_index": $tumor_bam_index,
            "cnvkit_tumor.normal_bam": $normal_bam,
            "cnvkit_tumor.normal_bam_index": $normal_bam_index,
            "cnvkit_tumor.ref_fasta": $ref_fasta,
            "cnvkit_tumor.ref_fasta_index": $ref_fasta_index,
            "cnvkit_tumor.refFlat": $refFlat,
            "cnvkit_tumor.threads": $threads
          }' > /scratch/cnvkit_inputs.json

        # Run CNVKit
        echo "Running CNVKit..."
        set +e
        CNVKIT_OUTPUT=$(miniwdl run \
          "${TASK_DIR}/HiFi-somatic-WDL-0.9.2/tasks/cnvkit.wdl" \
          --task cnvkit_tumor \
          --dir /scratch \
          --runtime-cpu-max=$AGENT_CPU_CORES \
          --runtime-memory-max=${AGENT_MEMORY_GB}G \
          --no-cache \
          -i /scratch/cnvkit_inputs.json 2>/dev/null)
        CNVKIT_OUTPUT_EXIT_CODE=$?
        if [ $CNVKIT_OUTPUT_EXIT_CODE -ne 0 ]; then
          handle_miniwdl_failure $CNVKIT_OUTPUT_EXIT_CODE
        fi
        
        # Post-execution logging for CNVKit
        CNVKIT_END_TIME=$(date +%s)
        CNVKIT_DURATION=$((CNVKIT_END_TIME - CNVKIT_START_TIME))
        CNVKIT_DURATION_HOUR=$((CNVKIT_DURATION / 3600))
        CNVKIT_DURATION_MIN=$(((CNVKIT_DURATION % 3600) / 60))
        CNVKIT_DURATION_SEC=$((CNVKIT_DURATION % 60))
        
        echo "================================================"
        echo "âœ… CNVKIT ANALYSIS COMPLETED SUCCESSFULLY"
        echo "================================================"
        echo "â±ï¸  Execution Time: ${CNVKIT_DURATION_HOUR}h ${CNVKIT_DURATION_MIN}m ${CNVKIT_DURATION_SEC}s"
        
        # Extract output file paths from CNVKIT_OUTPUT
        CNVKIT_CNR=$(echo "$CNVKIT_OUTPUT" | jq -r '.outputs."cnvkit_tumor.cnr"')
        CNVKIT_CNS=$(echo "$CNVKIT_OUTPUT" | jq -r '.outputs."cnvkit_tumor.cns"')
        CNVKIT_CALLS=$(echo "$CNVKIT_OUTPUT" | jq -r '.outputs."cnvkit_tumor.calls"')
        
        # Calculate total output size
        CNVKIT_TOTAL_SIZE=0
        if [ -f "$CNVKIT_CNR" ]; then
          CNVKIT_TOTAL_SIZE=$((CNVKIT_TOTAL_SIZE + $(stat -c%s "$CNVKIT_CNR" 2>/dev/null || echo "0")))
        fi
        if [ -f "$CNVKIT_CNS" ]; then
          CNVKIT_TOTAL_SIZE=$((CNVKIT_TOTAL_SIZE + $(stat -c%s "$CNVKIT_CNS" 2>/dev/null || echo "0")))
        fi
        if [ -f "$CNVKIT_CALLS" ]; then
          CNVKIT_TOTAL_SIZE=$((CNVKIT_TOTAL_SIZE + $(stat -c%s "$CNVKIT_CALLS" 2>/dev/null || echo "0")))
        fi
        
        # Format total size
        if [ $CNVKIT_TOTAL_SIZE -ge 1073741824 ]; then
          CNVKIT_TOTAL_GB=$((CNVKIT_TOTAL_SIZE / 1024 / 1024 / 1024))
          CNVKIT_TOTAL_MB=$(((CNVKIT_TOTAL_SIZE % (1024 * 1024 * 1024)) / 1024 / 1024))
          CNVKIT_TOTAL_DECIMAL=$((CNVKIT_TOTAL_MB * 100 / 1024))
          CNVKIT_TOTAL_FORMATTED="${CNVKIT_TOTAL_GB}.${CNVKIT_TOTAL_DECIMAL} GB"
        elif [ $CNVKIT_TOTAL_SIZE -ge 1048576 ]; then
          CNVKIT_TOTAL_MB=$((CNVKIT_TOTAL_SIZE / 1024 / 1024))
          CNVKIT_TOTAL_KB=$(((CNVKIT_TOTAL_SIZE % (1024 * 1024)) / 1024))
          CNVKIT_TOTAL_DECIMAL=$((CNVKIT_TOTAL_KB * 100 / 1024))
          CNVKIT_TOTAL_FORMATTED="${CNVKIT_TOTAL_MB}.${CNVKIT_TOTAL_DECIMAL} MB"
        else
          CNVKIT_TOTAL_FORMATTED="${CNVKIT_TOTAL_SIZE} bytes"
        fi
        
        echo "ðŸ“ **Total Output Size: $CNVKIT_TOTAL_FORMATTED**"
        echo "ðŸ’¾ **Remaining Disk Space: $(df -h /scratch | tail -n 1 | awk '{print $4}')**"
        echo "ðŸ“ Output Files:"
        
        if [ -f "$CNVKIT_CNR" ]; then
          echo "  - CNR File: $(basename "$CNVKIT_CNR") ($(format_file_size "$CNVKIT_CNR"))"
        fi
        if [ -f "$CNVKIT_CNS" ]; then
          echo "  - CNS File: $(basename "$CNVKIT_CNS") ($(format_file_size "$CNVKIT_CNS"))"
        fi
        if [ -f "$CNVKIT_CALLS" ]; then
          echo "  - Calls File: $(basename "$CNVKIT_CALLS") ($(format_file_size "$CNVKIT_CALLS"))"
        fi
        echo "================================================"
        
        echo "CNVKit output: $CNVKIT_OUTPUT"

        echo "Structural variant analysis completed successfully"
        echo "Copying output files to $output_folder..."

        # Copy Severus outputs
        echo "Copying Severus outputs..."
        cp -r ${tumor_sample_name}_severus "$output_folder/" 2>/dev/null || echo "Warning: Severus output directory not found"

        # Copy Wakhan outputs
        echo "Copying Wakhan outputs..."
        cp ${tumor_sample_name}_wakhan.tar.gz "$output_folder/" 2>/dev/null || echo "Warning: Wakhan tar file not found"
        cp purity_ploidy.tsv "$output_folder/" 2>/dev/null || echo "Warning: purity_ploidy.tsv not found"
        cp ${tumor_sample_name}.copynumbers_segments.bed "$output_folder/" 2>/dev/null || echo "Warning: copynumbers_segments.bed not found"
        cp ${tumor_sample_name}.loh_regions.bed "$output_folder/" 2>/dev/null || echo "Warning: loh_regions.bed not found"
        cp ${tumor_sample_name}.cancer_genes_copynumber.bed "$output_folder/" 2>/dev/null || echo "Warning: cancer_genes_copynumber.bed not found"

        # Copy Chord HRD outputs
        echo "Copying Chord HRD outputs..."
        if [ -n "$CHORD_HRD_LOG" ] && [ "$CHORD_HRD_LOG" != "null" ]; then
          cp "$CHORD_HRD_LOG" "$output_folder/" 2>/dev/null || echo "Warning: Chord HRD log file not found"
        fi
        if [ -n "$CHORD_HRD_PREDICTION" ] && [ "$CHORD_HRD_PREDICTION" != "null" ]; then
          cp "$CHORD_HRD_PREDICTION" "$output_folder/" 2>/dev/null || echo "Warning: Chord HRD prediction file not found"
        fi
        if [ -n "$CHORD_HRD_SIGNATURE" ] && [ "$CHORD_HRD_SIGNATURE" != "null" ]; then
          cp "$CHORD_HRD_SIGNATURE" "$output_folder/" 2>/dev/null || echo "Warning: Chord HRD signature file not found"
        fi

        # Copy CNVKit outputs
        echo "Copying CNVKit outputs..."
        CNVKIT_FILES=$(echo "$CNVKIT_OUTPUT" | jq -r '.outputs["cnvkit_tumor.cnvkit_output"] | join(" ")')
        if [ -n "$CNVKIT_FILES" ] && [ "$CNVKIT_FILES" != "null" ]; then
          for file in $CNVKIT_FILES; do
            cp "$file" "$output_folder/" 2>/dev/null || echo "Warning: CNVKit file $file not found"
          done
        else
          echo "Warning: CNVKit output files not found in results"
        fi

        echo "All output files copied to: $output_folder"
