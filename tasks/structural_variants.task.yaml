name: Structural Variant Calling
description: Call structural variants with Severus, Wakhan, and CNVKit

agent_requirements: 
  cpu_cores: 32
  memory_gb: 64

parameters: 
  - name: tumor_sample_name
    label: Sample Name (tumor)
    type: string
    help: "The name of the tumor sample with BAMs and VCFs to be phased."

  - name: normal_sample_name
    label: Sample Name (normal)
    type: string
    optional: true
    help: "The name of the normal sample with VCFs to be phased (note that only a tumor BAM is phased). If not provided, the workflow will run in tumor-only mode."

  - name: input_folder
    label: Input Folder
    type: directory
    supports_location_mode: 'no_append'
    help: "The folder containing the input files."

  - name: output_folder
    label: Output Folder
    type: directory
    supports_location_mode: 'no_append'

  - name: cache_udocker_images
    label: Cache Udocker Image
    type: boolean
    value: true

steps: 
  - name: structural_variants
    type: cmd
    description: Call structural variants with Severus, Wakhan, and CNVKit
    args: 
      - |- # shell
        set -eu pipefail

        echo "*************************"
        echo "Starting Structural Variant Analysis Task"
        echo "Space on agent: $(df -h /scratch | tail -n 1 | awk '{print $4}')"
        echo "Input Parameters:"
        echo "  - tumor_sample_name: $tumor_sample_name"
        echo "  - normal_sample_name: $normal_sample_name"
        echo "  - input_folder: $input_folder"
        echo "  - output_folder: $output_folder"
        echo "  - cache_udocker_images: $cache_udocker_images"
        echo "*************************"

        # Source common utility functions
        source "$TASK_DIR/utils/utils.sh"
        export MINIWDL__SCHEDULER__CONTAINER_BACKEND=udocker
        export MINIWDL__FILE_IO__ALLOW_ANY_INPUT=true
        export MINIWDL__SCHEDULER__TASK_CONCURRENCY=8
        export UDOCKER_DIR=/scratch/.udocker

        # Set up resource path
        PB_RESOURCES_DIR="${WORKSPACE_DIR}/${RESOURCES_PATH}/hifisomatic_resources"

        # Gather inputs

        echo "*************************"
        echo "Gathering reference files..."
        echo "Space on agent: $(df -h /scratch | tail -n 1 | awk '{print $4}')"
        echo "*************************"
        
        # Reference files
        REF_FASTA="${PB_RESOURCES_DIR}/GCA_000001405.15_GRCh38_no_alt_analysis_set_maskedGRC_exclusions_v2.fasta"
        REF_INDEX="${PB_RESOURCES_DIR}/GCA_000001405.15_GRCh38_no_alt_analysis_set_maskedGRC_exclusions_v2.fasta.fai"
        REF_FLAT="${PB_RESOURCES_DIR}/refFlat.hg38.txt"

        # Verify reference files exist
        if [ ! -f "$REF_FASTA" ]; then
          echo "Error: Reference FASTA file not found at $REF_FASTA"
          echo "Please ensure the PacBio WDL resources have been downloaded using the Download PacBio Reference Data Resources task"
          exit 1
        fi
        
        if [ ! -f "$REF_INDEX" ]; then
          echo "Error: Reference FASTA index file not found at $REF_INDEX"
          echo "Please ensure the PacBio WDL resources have been downloaded using the Download PacBio Reference Data Resources task"
          exit 1
        fi
        
        if [ ! -f "$REF_FLAT" ]; then
          echo "Error: Reference FLAT file not found at $REF_FLAT"
          echo "Please ensure the PacBio WDL resources have been downloaded using the Download PacBio Reference Data Resources task"
          exit 1
        fi

        # Copy reference files to /scratch
        echo "Copying reference files to /scratch..."
        copy_with_progress "/scratch" "$REF_FASTA" "$REF_INDEX" "$REF_FLAT"

        # Set local file paths
        LOCAL_REF_FASTA="/scratch/$(basename "$REF_FASTA")"
        LOCAL_REF_INDEX="/scratch/$(basename "$REF_INDEX")"
        LOCAL_REF_FLAT="/scratch/$(basename "$REF_FLAT")"
        
        # Verify reference files were copied successfully
        echo "Verifying reference files in /scratch..."
        if [ ! -f "$LOCAL_REF_FASTA" ]; then
          echo "Error: Reference FASTA file not found at $LOCAL_REF_FASTA after copying"
          echo "Original file: $REF_FASTA"
          echo "Files in /scratch:"
          ls -la /scratch/ | grep -E "\.(fasta|fa)$" || echo "No FASTA files found in /scratch"
          exit 1
        fi
        if [ ! -f "$LOCAL_REF_INDEX" ]; then
          echo "Error: Reference FASTA index file not found at $LOCAL_REF_INDEX after copying"
          echo "Original file: $REF_INDEX"
          exit 1
        fi
        if [ ! -f "$LOCAL_REF_FLAT" ]; then
          echo "Error: Reference FLAT file not found at $LOCAL_REF_FLAT after copying"
          echo "Original file: $REF_FLAT"
          exit 1
        fi
        echo "‚úì All reference files verified in /scratch"

        echo "*************************"
        echo "Gathering tumor and normal input files..."
        echo "Space on agent: $(df -h /scratch | tail -n 1 | awk '{print $4}')"
        echo "*************************"

        TUMOR_BAM="${input_folder}/${tumor_sample_name}.hiphase.bam"
        TUMOR_BAM_INDEX="${input_folder}/${tumor_sample_name}.hiphase.bam.bai"
        TUMOR_PHASED_VCF="${input_folder}/${tumor_sample_name}.clair3.small_variants.correct_ref.phased.vcf.gz"
        TUMOR_PHASED_VCF_INDEX="${TUMOR_PHASED_VCF}.tbi"
        TUMOR_SOMATIC_VCF="${input_folder}/${tumor_sample_name}.deepsomatic.phased.vcf.gz"
        TUMOR_SOMATIC_VCF_INDEX="${TUMOR_SOMATIC_VCF}.tbi"
        if [ -z "${normal_sample_name}" ]; then
          echo "Warning: Normal sample name not provided - running tumor-only analysis"
        else
          NORMAL_BAM="${input_folder}/${normal_sample_name}.hiphase.bam"
          NORMAL_BAM_INDEX="${input_folder}/${normal_sample_name}.hiphase.bam.bai"
          NORMAL_PHASED_VCF="${input_folder}/${normal_sample_name}.clair3.small_variants.correct_ref.phased.vcf.gz"
          NORMAL_PHASED_VCF_INDEX="${NORMAL_PHASED_VCF}.tbi"
        fi
        TRF_BED="${PB_RESOURCES_DIR}/human_GRCh38_no_alt_analysis_set.trf.bed"

        # Check inputs exist
        if [ ! -f "$TUMOR_BAM" ]; then
          echo "Error: Tumor BAM file not found at $TUMOR_BAM"
          exit 1
        fi
        if [ ! -f "$TUMOR_BAM_INDEX" ]; then
          echo "Error: Tumor BAM index file not found at $TUMOR_BAM_INDEX"
          exit 1
        fi
        if [ ! -f "$TUMOR_PHASED_VCF" ]; then
          echo "Error: Tumor phased VCF file not found at $TUMOR_PHASED_VCF"
          exit 1
        fi
        if [ ! -f "$TUMOR_PHASED_VCF_INDEX" ]; then
          echo "Error: Tumor phased VCF index file not found at $TUMOR_PHASED_VCF_INDEX"
          exit 1
        fi
        if [ ! -f "$TUMOR_SOMATIC_VCF" ]; then
          echo "Error: Tumor somatic VCF file not found at $TUMOR_SOMATIC_VCF"
          exit 1
        fi
        if [ ! -f "$TUMOR_SOMATIC_VCF_INDEX" ]; then
          echo "Error: Tumor somatic VCF index file not found at $TUMOR_SOMATIC_VCF_INDEX"
          exit 1
        fi
        if [ -z "${normal_sample_name}" ]; then
          echo "Warning: Normal sample name not provided - running tumor-only analysis"
        else
          if [ ! -f "$NORMAL_BAM" ]; then
            echo "Error: Normal BAM file not found at $NORMAL_BAM"
            exit 1
          fi
          if [ ! -f "$NORMAL_BAM_INDEX" ]; then
            echo "Error: Normal BAM index file not found at $NORMAL_BAM_INDEX"
            exit 1
          fi
          if [ ! -f "$NORMAL_PHASED_VCF" ]; then
            echo "Error: Normal phased VCF file not found at $NORMAL_PHASED_VCF"
            exit 1
          fi
          if [ ! -f "$NORMAL_PHASED_VCF_INDEX" ]; then
            echo "Error: Normal phased VCF index file not found at $NORMAL_PHASED_VCF_INDEX"
            exit 1
          fi
        fi
        if [ ! -f "$TRF_BED" ]; then
          echo "Error: TRF BED file not found at $TRF_BED"
          exit 1
        fi

        # Copy inputs to /scratch
        echo "Copying tumor and normal input files to /scratch..."
        copy_with_progress /scratch "$TUMOR_BAM" "$TUMOR_BAM_INDEX" "$TUMOR_PHASED_VCF" "$TUMOR_PHASED_VCF_INDEX" "$TRF_BED" "$TUMOR_SOMATIC_VCF" "$TUMOR_SOMATIC_VCF_INDEX"
        if [ -z "${normal_sample_name}" ]; then
          echo "Warning: Normal sample name not provided - running tumor-only analysis"
        else
          copy_with_progress /scratch "$NORMAL_BAM" "$NORMAL_BAM_INDEX" "$NORMAL_PHASED_VCF" "$NORMAL_PHASED_VCF_INDEX"
        fi

        # Set local file paths
        LOCAL_TUMOR_BAM="/scratch/$(basename "${TUMOR_BAM}")"
        LOCAL_TUMOR_BAM_INDEX="/scratch/$(basename "${TUMOR_BAM_INDEX}")"
        LOCAL_TUMOR_PHASED_VCF="/scratch/$(basename "${TUMOR_PHASED_VCF}")"
        LOCAL_TUMOR_PHASED_VCF_INDEX="/scratch/$(basename "${TUMOR_PHASED_VCF_INDEX}")"
        LOCAL_NORMAL_BAM="/scratch/$(basename "${NORMAL_BAM}")"
        LOCAL_NORMAL_BAM_INDEX="/scratch/$(basename "${NORMAL_BAM_INDEX}")"
        LOCAL_NORMAL_PHASED_VCF="/scratch/$(basename "${NORMAL_PHASED_VCF}")"
        LOCAL_NORMAL_PHASED_VCF_INDEX="/scratch/$(basename "${NORMAL_PHASED_VCF_INDEX}")"
        LOCAL_TRF_BED="/scratch/$(basename "${TRF_BED}")"
        LOCAL_TUMOR_SOMATIC_VCF="/scratch/$(basename "${TUMOR_SOMATIC_VCF}")"
        LOCAL_TUMOR_SOMATIC_VCF_INDEX="/scratch/$(basename "${TUMOR_SOMATIC_VCF_INDEX}")"

        echo "*************************"
        echo "Starting Severus analysis for $tumor_sample_name"
        echo "*************************"
        
        # Severus:
        # - Tumor BAM
        # - Tumor BAM Index
        # - Normal BAM
        # - Normal BAM Index
        # - Normal Phased VCF
        # - TRF BED
        # - PON TSV (note: this is optional in the WDL workflow, so ignoring it here)

        # Check if Severus outputs already exist
        echo "Checking if Severus outputs already exist..."
        SEVERUS_OUTPUT_VCF="${output_folder}/${tumor_sample_name}.severus_somatic.vcf.gz"
        SEVERUS_ALL_VCF="${output_folder}/${tumor_sample_name}.severus_all.vcf.gz"
        
        if [ -f "$SEVERUS_OUTPUT_VCF" ] && [ -f "$SEVERUS_ALL_VCF" ]; then
          echo "Severus outputs already exist. Skipping Severus step."
          echo "  - Somatic SV VCF: $(basename "$SEVERUS_OUTPUT_VCF") ($(format_file_size "$SEVERUS_OUTPUT_VCF"))"
          echo "  - All SV VCF: $(basename "$SEVERUS_ALL_VCF") ($(format_file_size "$SEVERUS_ALL_VCF"))"
          
          # Set variables to simulate successful completion for downstream steps
          SEVERUS_SOMATIC_VCF="$SEVERUS_OUTPUT_VCF"
          SEVERUS_ALL_VCF="$SEVERUS_ALL_VCF"
          SEVERUS_OUTPUT='{"outputs":{"Severus_sv.output_vcf":"'$SEVERUS_OUTPUT_VCF'","Severus_sv.output_all_vcf":"'$SEVERUS_ALL_VCF'"}}'

        else
          echo "Severus outputs missing. Proceeding with Severus analysis..."

          # Pre-execution logging for Severus
          echo "================================================"
          echo "üöÄ STARTING SEVERUS ANALYSIS"
          echo "================================================"
          echo "üìÖ Server Time: $(date)"
          echo "üìÅ Input Files:"
          echo "  - Tumor BAM: $(basename "$LOCAL_TUMOR_BAM") ($(format_file_size "$LOCAL_TUMOR_BAM"))"
          echo "  - Tumor BAM Index: $(basename "$LOCAL_TUMOR_BAM_INDEX") ($(format_file_size "$LOCAL_TUMOR_BAM_INDEX"))"
          echo "  - Normal BAM: $(basename "$LOCAL_NORMAL_BAM") ($(format_file_size "$LOCAL_NORMAL_BAM"))"
          echo "  - Normal BAM Index: $(basename "$LOCAL_NORMAL_BAM_INDEX") ($(format_file_size "$LOCAL_NORMAL_BAM_INDEX"))"
          echo "  - Normal Phased VCF: $(basename "$LOCAL_NORMAL_PHASED_VCF") ($(format_file_size "$LOCAL_NORMAL_PHASED_VCF"))"
          echo "  - TRF BED: $(basename "$LOCAL_TRF_BED") ($(format_file_size "$LOCAL_TRF_BED"))"
          echo "‚öôÔ∏è  Configuration:"
          echo "  - Threads: $AGENT_CPU_CORES"
          echo "  - Min Support Reads: 3"
          echo "================================================"
          
          # Record start time
          SEVERUS_START_TIME=$(date +%s)
          
          # Run Severus
          echo "Running Severus..."
          jq -n \
            --arg pname "$tumor_sample_name" \
            --arg bam "$LOCAL_TUMOR_BAM" \
            --arg bam_index "$LOCAL_TUMOR_BAM_INDEX" \
            --arg normal_bam "$LOCAL_NORMAL_BAM" \
            --arg normal_bam_index "$LOCAL_NORMAL_BAM_INDEX" \
            --arg phased_vcf "$LOCAL_NORMAL_PHASED_VCF" \
            --arg trf_bed "$LOCAL_TRF_BED" \
            --argjson threads "$AGENT_CPU_CORES" \
            --argjson min_supp_reads 3 \
            '{
              "Severus_sv.pname": $pname,
              "Severus_sv.tumor_bam": $bam,
              "Severus_sv.tumor_bam_index": $bam_index,
              "Severus_sv.normal_bam": $normal_bam,
              "Severus_sv.normal_bam_index": $normal_bam_index,
              "Severus_sv.phased_vcf": $phased_vcf,
              "Severus_sv.trf_bed": $trf_bed,
              "Severus_sv.threads": $threads,
              "Severus_sv.min_supp_reads": $min_supp_reads
            }' > /scratch/severus_inputs.json

          set +e
          SEVERUS_OUTPUT=$(miniwdl run \
            "${TASK_DIR}/HiFi-somatic-WDL-0.9.2/tasks/structural_variants_updated.wdl" \
            --task Severus_sv \
            --dir /scratch \
            --runtime-cpu-max=$AGENT_CPU_CORES \
            --runtime-memory-max=${AGENT_MEMORY_GB}G \
            --no-cache \
            -i /scratch/severus_inputs.json 2>/dev/null)
          SEVERUS_OUTPUT_EXIT_CODE=$?
          if [ $SEVERUS_OUTPUT_EXIT_CODE -ne 0 ]; then
            handle_miniwdl_failure $SEVERUS_OUTPUT_EXIT_CODE
          fi
          
          # Extract output file paths from SEVERUS_OUTPUT
          SEVERUS_SOMATIC_VCF=$(echo "$SEVERUS_OUTPUT" | jq -r '.outputs."Severus_sv.output_vcf"')
          SEVERUS_ALL_VCF=$(echo "$SEVERUS_OUTPUT" | jq -r '.outputs."Severus_sv.output_all_vcf"')

          # Copy Severus outputs immediately after completion
          echo "Copying Severus outputs..."
          SEVERUS_OUTPUT_FILES=()
          if [ -f "$SEVERUS_SOMATIC_VCF" ]; then
            # Rename to include sample name prefix
            SEVERUS_RENAMED_SOMATIC="${output_folder}/${tumor_sample_name}.severus_somatic.vcf.gz"
            cp "$SEVERUS_SOMATIC_VCF" "$SEVERUS_RENAMED_SOMATIC"
            SEVERUS_OUTPUT_FILES+=("$SEVERUS_RENAMED_SOMATIC")
          fi
          if [ -f "$SEVERUS_ALL_VCF" ]; then
            # Rename to include sample name prefix
            SEVERUS_RENAMED_ALL="${output_folder}/${tumor_sample_name}.severus_all.vcf.gz"
            cp "$SEVERUS_ALL_VCF" "$SEVERUS_RENAMED_ALL"
            SEVERUS_OUTPUT_FILES+=("$SEVERUS_RENAMED_ALL")
          fi
          if [ ${#SEVERUS_OUTPUT_FILES[@]} -gt 0 ]; then
            echo "Severus outputs copied with sample name prefix"
          fi

          # Update vspipeline_inputs.json with Severus VCF files
          echo "Updating vspipeline_inputs.json for Severus outputs..."
          if ! command -v python3 &> /dev/null; then
            echo "Warning: python3 not available, skipping vspipeline_inputs.json update"
          else
            # Add Severus somatic VCF to bnd
            SEVERUS_SOMATIC_VCF="${output_folder}/${tumor_sample_name}.severus_somatic.vcf.gz"
            if [ -f "$SEVERUS_SOMATIC_VCF" ]; then
              RELATIVE_PATH="${SEVERUS_SOMATIC_VCF#${WORKSPACE_DIR}/}"
              python3 "${TASK_DIR}/vspipeline-resources/vspipeline_utilities.py" update-vspipeline-json \
                --input_dir "$output_folder" \
                --sample "$tumor_sample_name" \
                --file "$RELATIVE_PATH" \
                --file_type bnd \
                --task_name severus \
                --scratch_dir /scratch || \
                { echo "Warning: Failed to update vspipeline_inputs.json for Severus somatic VCF, continuing..."; }
            fi
          fi
          
          # Post-execution logging for Severus
          SEVERUS_END_TIME=$(date +%s)
          SEVERUS_DURATION=$((SEVERUS_END_TIME - SEVERUS_START_TIME))
          SEVERUS_DURATION_HOUR=$((SEVERUS_DURATION / 3600))
          SEVERUS_DURATION_MIN=$(((SEVERUS_DURATION % 3600) / 60))
          SEVERUS_DURATION_SEC=$((SEVERUS_DURATION % 60))

          echo "================================================"
          echo "‚úÖ SEVERUS ANALYSIS COMPLETED SUCCESSFULLY"
          echo "================================================"
          echo "‚è±Ô∏è  Execution Time: ${SEVERUS_DURATION_HOUR}h ${SEVERUS_DURATION_MIN}m ${SEVERUS_DURATION_SEC}s"
          
          # Calculate total output size
          SEVERUS_TOTAL_SIZE=0
          if [ -f "$SEVERUS_SOMATIC_VCF" ]; then
            SEVERUS_TOTAL_SIZE=$((SEVERUS_TOTAL_SIZE + $(stat -c%s "$SEVERUS_SOMATIC_VCF" 2>/dev/null || echo "0")))
          fi
          if [ -f "$SEVERUS_ALL_VCF" ]; then
            SEVERUS_TOTAL_SIZE=$((SEVERUS_TOTAL_SIZE + $(stat -c%s "$SEVERUS_ALL_VCF" 2>/dev/null || echo "0")))
          fi
          
          # Format total size
          if [ $SEVERUS_TOTAL_SIZE -ge 1073741824 ]; then
            SEVERUS_TOTAL_GB=$((SEVERUS_TOTAL_SIZE / 1024 / 1024 / 1024))
            SEVERUS_TOTAL_MB=$(((SEVERUS_TOTAL_SIZE % (1024 * 1024 * 1024)) / 1024 / 1024))
            SEVERUS_TOTAL_DECIMAL=$((SEVERUS_TOTAL_MB * 100 / 1024))
            SEVERUS_TOTAL_FORMATTED="${SEVERUS_TOTAL_GB}.${SEVERUS_TOTAL_DECIMAL} GB"
          elif [ $SEVERUS_TOTAL_SIZE -ge 1048576 ]; then
            SEVERUS_TOTAL_MB=$((SEVERUS_TOTAL_SIZE / 1024 / 1024))
            SEVERUS_TOTAL_KB=$(((SEVERUS_TOTAL_SIZE % (1024 * 1024)) / 1024))
            SEVERUS_TOTAL_DECIMAL=$((SEVERUS_TOTAL_KB * 100 / 1024))
            SEVERUS_TOTAL_FORMATTED="${SEVERUS_TOTAL_MB}.${SEVERUS_TOTAL_DECIMAL} MB"
          else
            SEVERUS_TOTAL_FORMATTED="${SEVERUS_TOTAL_SIZE} bytes"
          fi
          
          echo "üìÅ **Total Output Size: $SEVERUS_TOTAL_FORMATTED**"
          echo "üíæ **Remaining Disk Space: $(df -h /scratch | tail -n 1 | awk '{print $4}')**"
          echo "üìÅ Output Files:"
          
          if [ -f "$SEVERUS_SOMATIC_VCF" ]; then
            echo "  - Somatic SV VCF: $(basename "$SEVERUS_SOMATIC_VCF") ($(format_file_size "$SEVERUS_SOMATIC_VCF"))"
          fi
          if [ -f "$SEVERUS_ALL_VCF" ]; then
            echo "  - All SV VCF: $(basename "$SEVERUS_ALL_VCF") ($(format_file_size "$SEVERUS_ALL_VCF"))"
          fi
          echo "================================================"
          
        fi

        # Fix Severus VCF sample names and create indices
        echo "*************************"
        echo "Fixing Severus VCF sample names and creating indices..."
        echo "Space on agent: $(df -h /scratch | tail -n 1 | awk '{print $4}')"
        echo "*************************"
        
        # Copy Severus VCFs to /scratch before processing
        SEVERUS_SOMATIC_INPUT="${output_folder}/${tumor_sample_name}.severus_somatic.vcf.gz"
        SEVERUS_ALL_INPUT="${output_folder}/${tumor_sample_name}.severus_all.vcf.gz"
        
        SEVERUS_SOMATIC_LOCAL="/scratch/${tumor_sample_name}.severus_somatic.vcf.gz"
        SEVERUS_ALL_LOCAL="/scratch/${tumor_sample_name}.severus_all.vcf.gz"
        
        # Copy Severus somatic VCF to /scratch if it exists
        if [ -f "$SEVERUS_SOMATIC_INPUT" ]; then
          echo "Copying Severus somatic VCF to /scratch..."
          cp "$SEVERUS_SOMATIC_INPUT" "$SEVERUS_SOMATIC_LOCAL"
          if [ -f "${SEVERUS_SOMATIC_INPUT}.tbi" ]; then
            cp "${SEVERUS_SOMATIC_INPUT}.tbi" "${SEVERUS_SOMATIC_LOCAL}.tbi"
          fi
        fi
        
        # Copy Severus all VCF to /scratch if it exists
        if [ -f "$SEVERUS_ALL_INPUT" ]; then
          echo "Copying Severus all VCF to /scratch..."
          cp "$SEVERUS_ALL_INPUT" "$SEVERUS_ALL_LOCAL"
          if [ -f "${SEVERUS_ALL_INPUT}.tbi" ]; then
            cp "${SEVERUS_ALL_INPUT}.tbi" "${SEVERUS_ALL_LOCAL}.tbi"
          fi
        fi
        
        # Process Severus somatic VCF
        if [ -f "$SEVERUS_SOMATIC_LOCAL" ]; then
          echo "Processing Severus somatic VCF: $(basename "$SEVERUS_SOMATIC_LOCAL")"
          
          # Check if sample names need fixing
          NEEDS_FIXING=$(bcftools view -h "$SEVERUS_SOMATIC_LOCAL" | grep -E "^#CHROM|^#FORMAT" | grep -c "\.hiphase" 2>/dev/null || echo "0")
          NEEDS_FIXING=$(echo "$NEEDS_FIXING" | tr -d '\n\r')
          
          if [ "$NEEDS_FIXING" -gt 0 ]; then
            echo "  - Sample names need fixing, processing..."
            
            # Create temporary file for processing
            SEVERUS_SOMATIC_TEMP="/scratch/${tumor_sample_name}.severus_somatic.temp.vcf"
            
            # Fix sample names (remove .hiphase suffix)
            bcftools view -h "$SEVERUS_SOMATIC_LOCAL" | sed "s/${tumor_sample_name}\.hiphase/${tumor_sample_name}/g" > "$SEVERUS_SOMATIC_TEMP"
            bcftools view -H "$SEVERUS_SOMATIC_LOCAL" >> "$SEVERUS_SOMATIC_TEMP"
            
            # Compress and replace local file
            bgzip -c "$SEVERUS_SOMATIC_TEMP" > "$SEVERUS_SOMATIC_LOCAL"
            rm -f "$SEVERUS_SOMATIC_TEMP"
            
            echo "  - Sample names fixed"
          else
            echo "  - Sample names already correct"
          fi
          
          # Create TBI index (check if it doesn't already exist)
          if [ ! -f "${SEVERUS_SOMATIC_LOCAL}.tbi" ]; then
            tabix -f -p vcf "$SEVERUS_SOMATIC_LOCAL" || { echo "  - Warning: Failed to create TBI index"; if [ ! -f "${SEVERUS_SOMATIC_LOCAL}.tbi" ]; then echo "  - Index file does not exist"; else echo "  - Index file exists, continuing..."; fi; }
            if [ -f "${SEVERUS_SOMATIC_LOCAL}.tbi" ]; then
              echo "  - Created TBI index"
            fi
          else
            echo "  - TBI index already exists"
          fi
        fi
        
        # Process Severus all VCF
        if [ -f "$SEVERUS_ALL_LOCAL" ]; then
          echo "Processing Severus all VCF: $(basename "$SEVERUS_ALL_LOCAL")"
          
          # Check if sample names need fixing
          NEEDS_FIXING=$(bcftools view -h "$SEVERUS_ALL_LOCAL" | grep -E "^#CHROM|^#FORMAT" | grep -c "\.hiphase" 2>/dev/null || echo "0")
          NEEDS_FIXING=$(echo "$NEEDS_FIXING" | tr -d '\n\r')
          
          if [ "$NEEDS_FIXING" -gt 0 ]; then
            echo "  - Sample names need fixing, processing..."
            
            # Create temporary file for processing
            SEVERUS_ALL_TEMP="/scratch/${tumor_sample_name}.severus_all.temp.vcf"
            
            # Fix sample names (remove .hiphase suffix from both tumor and normal samples)
            if [ -n "${normal_sample_name}" ]; then
              bcftools view -h "$SEVERUS_ALL_LOCAL" | sed "s/${tumor_sample_name}\.hiphase/${tumor_sample_name}/g; s/${normal_sample_name}\.hiphase/${normal_sample_name}/g" > "$SEVERUS_ALL_TEMP"
            else
              bcftools view -h "$SEVERUS_ALL_LOCAL" | sed "s/${tumor_sample_name}\.hiphase/${tumor_sample_name}/g" > "$SEVERUS_ALL_TEMP"
            fi
            bcftools view -H "$SEVERUS_ALL_LOCAL" >> "$SEVERUS_ALL_TEMP"
            
            # Compress and replace local file
            bgzip -c "$SEVERUS_ALL_TEMP" > "$SEVERUS_ALL_LOCAL"
            rm -f "$SEVERUS_ALL_TEMP"
            
            echo "  - Sample names fixed"
          else
            echo "  - Sample names already correct"
          fi
          
          # Create TBI index (check if it doesn't already exist)
          if [ ! -f "${SEVERUS_ALL_LOCAL}.tbi" ]; then
            tabix -f -p vcf "$SEVERUS_ALL_LOCAL" || { echo "  - Warning: Failed to create TBI index"; if [ ! -f "${SEVERUS_ALL_LOCAL}.tbi" ]; then echo "  - Index file does not exist"; else echo "  - Index file exists, continuing..."; fi; }
            if [ -f "${SEVERUS_ALL_LOCAL}.tbi" ]; then
              echo "  - Created TBI index"
            fi
          else
            echo "  - TBI index already exists"
          fi
        fi
        
        # Update variables to point to the fixed VCFs in /scratch for downstream steps
        if [ -f "$SEVERUS_SOMATIC_LOCAL" ]; then
          SEVERUS_SOMATIC_VCF="$SEVERUS_SOMATIC_LOCAL"
        fi

        if [ -f "$SEVERUS_ALL_LOCAL" ]; then
          SEVERUS_ALL_VCF="$SEVERUS_ALL_LOCAL"
        fi
        
        echo "Severus VCF processing completed successfully"
      
        # Wakhan:
        # - Tumor BAM
        # - Tumor BAM index 
        # - Reference FASTA
        # - Reference FASTA index
        # - Severus SV VCF
        # - Normal Phased VCF
        # - Tumor Phased VCF

        # Check if Wakhan outputs already exist
        echo "Checking if Wakhan outputs already exist..."
        WAKHAN_CNA_INTEGERS_VCF="${output_folder}/${tumor_sample_name}.wakhan_cna_integers.vcf.gz"
        WAKHAN_CNA_SUBCLONALS_VCF="${output_folder}/${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz"
        
        if [ -f "$WAKHAN_CNA_INTEGERS_VCF" ] && [ -f "${WAKHAN_CNA_INTEGERS_VCF}.tbi" ] && [ -f "$WAKHAN_CNA_SUBCLONALS_VCF" ] && [ -f "${WAKHAN_CNA_SUBCLONALS_VCF}.tbi" ]; then
          echo "Wakhan outputs already exist. Skipping Wakhan step."
          echo "  - CNA Integers VCF: $(basename "$WAKHAN_CNA_INTEGERS_VCF") ($(format_file_size "$WAKHAN_CNA_INTEGERS_VCF"))"
          echo "  - CNA Subclonals VCF: $(basename "$WAKHAN_CNA_SUBCLONALS_VCF") ($(format_file_size "$WAKHAN_CNA_SUBCLONALS_VCF"))"
        else
          echo "Wakhan outputs missing. Proceeding with Wakhan analysis..."

          # Pre-execution logging for Wakhan
          echo "================================================"
          echo "üöÄ STARTING WAKHAN ANALYSIS"
          echo "================================================"
          echo "üìÖ Server Time: $(date)"
          echo "üìÅ Input Files:"
          echo "  - Tumor BAM: $(basename "$LOCAL_TUMOR_BAM") ($(format_file_size "$LOCAL_TUMOR_BAM"))"
          echo "  - Tumor BAM Index: $(basename "$LOCAL_TUMOR_BAM_INDEX") ($(format_file_size "$LOCAL_TUMOR_BAM_INDEX"))"
          echo "  - Reference FASTA: $(basename "$LOCAL_REF_FASTA") ($(format_file_size "$LOCAL_REF_FASTA"))"
          echo "  - Reference FASTA Index: $(basename "$LOCAL_REF_INDEX") ($(format_file_size "$LOCAL_REF_INDEX"))"
          echo "  - Severus SV VCF: $(basename "$SEVERUS_SOMATIC_VCF") ($(format_file_size "$SEVERUS_SOMATIC_VCF"))"
          echo "  - Normal Phased VCF: $(basename "$LOCAL_NORMAL_PHASED_VCF") ($(format_file_size "$LOCAL_NORMAL_PHASED_VCF"))"
          echo "  - Tumor Phased VCF: $(basename "$LOCAL_TUMOR_PHASED_VCF") ($(format_file_size "$LOCAL_TUMOR_PHASED_VCF"))"
          echo "================================================"
          
          # Record start time
          WAKHAN_START_TIME=$(date +%s)

          # Download and install Wakhan directly from GitHub
          echo "Downloading and installing Wakhan..."
          set +e
          
          # Add local bin directory to PATH for pip-installed packages
          export PATH="$HOME/.local/bin:$PATH"
          
          # Check if Wakhan is already installed
          if command -v wakhan >/dev/null 2>&1; then
            echo "Wakhan is already installed, skipping installation..."
          else
            echo "Installing Wakhan dependencies and package..."
            
            # Install dependencies if not already available (suppress PATH warnings)
            pip install -q --no-warn-script-location setuptools pysam pyfaidx numpy pandas plotly scikit-learn scipy ruptures vcf_parser kaleido intervaltree > /dev/null 2>&1 || {
              echo "Failed to install Wakhan dependencies"
              exit 1
            }
            
            # Download and install Wakhan from GitHub
            cd /scratch
            if [ ! -d "Wakhan" ]; then
              git clone https://github.com/KolmogorovLab/Wakhan.git > /dev/null 2>&1 || {
                echo "Failed to clone Wakhan repository"
                exit 1
              }
            fi
            
            cd Wakhan
            pip install -q --no-warn-script-location -e . > /dev/null 2>&1 || {
              echo "Failed to install Wakhan package"
              exit 1
            }
            
            # Verify Wakhan is installed and accessible
            if command -v wakhan -h >/dev/null 2>&1; then
              echo "Wakhan installation successful"
            else
              echo "Wakhan installation verification failed - command not found in PATH"
              echo "PATH is: $PATH"
              echo "Checking for wakhan binary in common locations..."
              find "$HOME/.local/bin" -name "wakhan*" -type f 2>/dev/null || echo "No wakhan binary found in ~/.local/bin"
              exit 1
            fi

          fi
          
          cd /scratch

          # Copy Severus VCF to scratch with a simple name to avoid path issues
          LOCAL_SEVERUS_VCF="/scratch/${tumor_sample_name}.severus_somatic.vcf.gz"
          if [ ! -f "$LOCAL_SEVERUS_VCF" ]; then
            echo "Copying Severus VCF to scratch: $SEVERUS_SOMATIC_VCF -> $LOCAL_SEVERUS_VCF"
            cp "$SEVERUS_SOMATIC_VCF" "$LOCAL_SEVERUS_VCF" || { echo "Failed to copy Severus somatic VCF; probably already exists"; }
            cp "${SEVERUS_SOMATIC_VCF}.tbi" "${LOCAL_SEVERUS_VCF}.tbi" || { echo "Failed to copy Severus somatic VCF index; probably already exists"; }
          else
            echo "Severus VCF already exists in scratch: $LOCAL_SEVERUS_VCF"
          fi
          
          # Setup centromere annotation file
          CENTROMERE_BED="/scratch/Wakhan/src/annotations/grch38.cen_coord.curated.bed"
          
          # Set up gene annotation BED file
          GENES_BED="/scratch/Wakhan/src/annotations/COSMIC_cancer_genes.tsv"

          # Run Wakhan
          set +e
          echo "Running Wakhan..."
          
          # Build Wakhan command - follow WDL workflow pattern:
          # If normal VCF is provided: use --normal-phased-vcf only
          # If no normal VCF: use --tumor-vcf with --hets-ratio
          WAKHAN_CMD="wakhan \
            --threads $AGENT_CPU_CORES \
            --target-bam \"$LOCAL_TUMOR_BAM\" \
            --reference \"$LOCAL_REF_FASTA\" \
            --genome-name \"$tumor_sample_name\" \
            --out-dir \"${tumor_sample_name}_wakhan\" \
            --breakpoints \"$LOCAL_SEVERUS_VCF\" \
            --loh-enable \
            --ploidy-range 1-6 \
            --purity-range 0.2-1.0 \
            --centromere \"$CENTROMERE_BED\" \
            --cancer-genes \"$GENES_BED\""
          
          # Add VCF parameter based on whether normal sample is provided (matching WDL workflow)
          if [ -n "${normal_sample_name}" ] && [ -f "$LOCAL_NORMAL_PHASED_VCF" ]; then
            WAKHAN_CMD="$WAKHAN_CMD --normal-phased-vcf \"$LOCAL_NORMAL_PHASED_VCF\""
          else
            # If no normal VCF, use tumor VCF with hets-ratio as per WDL workflow
            WAKHAN_CMD="$WAKHAN_CMD --tumor-vcf \"$LOCAL_TUMOR_PHASED_VCF\" --hets-ratio 0.25"
          fi
          
          # Run Wakhan with output capture - don't suppress all output, capture it for debugging
          echo "Executing Wakhan command..."
          eval $WAKHAN_CMD > wakhan_output.log 2>wakhan_error.log
          WAKHAN_OUTPUT_EXIT_CODE=$?
          set -e
          
          # Initialize flag to track if Wakhan succeeded
          WAKHAN_SUCCEEDED=0
          
          if [ $WAKHAN_OUTPUT_EXIT_CODE -ne 0 ]; then
            echo "‚ö†Ô∏è  Wakhan failed with exit code $WAKHAN_OUTPUT_EXIT_CODE"
            echo "Continuing with downstream steps (Chord HRD, CNVKit) despite Wakhan failure..."
            echo ""
            echo "=== Wakhan Error Output ==="
            if [ -f "wakhan_error.log" ]; then
              cat wakhan_error.log
            else
              echo "No error log file found"
            fi
            echo ""
            echo "=== Wakhan Standard Output (last 50 lines) ==="
            if [ -f "wakhan_output.log" ]; then
              tail -n 50 wakhan_output.log || echo "Could not read output log"
            fi
            echo ""
            echo "=== Checking Wakhan output directory ==="
            if [ -d "${tumor_sample_name}_wakhan" ]; then
              echo "Output directory exists. Contents:"
              ls -la "${tumor_sample_name}_wakhan" || true
              if [ -f "${tumor_sample_name}_wakhan/solutions_ranks.tsv" ]; then
                echo "Solutions ranks file exists:"
                head -n 20 "${tumor_sample_name}_wakhan/solutions_ranks.tsv" || true
              else
                echo "WARNING: solutions_ranks.tsv not found - Wakhan may have found no valid solutions"
              fi
            else
              echo "Output directory does not exist"
            fi
            
            # Check if this is the specific IndexError we're tracking
            if grep -q "IndexError: list index out of range" wakhan_error.log 2>/dev/null || grep -q "IndexError: list index out of range" wakhan_output.log 2>/dev/null; then
              echo ""
              echo "=== Detected IndexError in Wakhan ==="
              echo "This error typically means Wakhan found no valid purity/ploidy solutions."
              echo "Possible causes:"
              echo "  1. Data quality issues (especially for sex chromosomes)"
              echo "  2. Purity/ploidy ranges too restrictive (currently: purity 0.2-1.0, ploidy 1-6)"
              echo "  3. Insufficient heterozygous variants in input VCFs"
              echo ""
              echo "Recommendations:"
              echo "  - Check input VCF quality and variant counts"
              echo "  - Consider expanding purity range (e.g., 0.1-1.0) or ploidy range"
              echo "  - Verify tumor and normal phased VCFs have sufficient variants"
            fi
            
            # Set flag to indicate Wakhan failed
            WAKHAN_SUCCEEDED=0
            echo ""
            echo "‚ö†Ô∏è  Skipping Wakhan output processing. Continuing with Chord HRD and CNVKit steps..."
          else
            # Check if solutions were found even if exit code was 0 (in case Wakhan doesn't properly exit on errors)
            if [ -d "${tumor_sample_name}_wakhan" ]; then
              if [ ! -f "${tumor_sample_name}_wakhan/solutions_ranks.tsv" ]; then
                echo "WARNING: Wakhan completed but solutions_ranks.tsv not found - no solutions may have been generated"
                echo "Checking for any output directories..."
                find "${tumor_sample_name}_wakhan" -type d -name "[0-9]*_[0-9]*_[0-9]*" | head -n 5 || echo "No solution directories found"
                echo "‚ö†Ô∏è  Wakhan may have failed to generate valid solutions. Skipping output processing..."
                WAKHAN_SUCCEEDED=0
              else
                WAKHAN_SUCCEEDED=1
              fi
            else
              echo "WARNING: Wakhan output directory not found. Skipping output processing..."
              WAKHAN_SUCCEEDED=0
            fi
          fi
          
          # Clean up log files
          rm -f wakhan_error.log wakhan_output.log

          # Process Wakhan outputs only if Wakhan succeeded
          if [ $WAKHAN_SUCCEEDED -eq 1 ]; then
            echo "Processing Wakhan outputs..."
            
            # Save purity and ploidy
            cd ${tumor_sample_name}_wakhan
            # Create TSV file with headers
            echo -e "folder_name\tploidy\tpurity\tconfidence" > folder_numbers.tsv

            # Find directories matching the pattern and process them
            find . -type d -regex ".*/[0-9.]+_[0-9.]+_[0-9.]+$" | while read dir; do
                # Get just the folder name without the path
                folder_name=$(basename "$dir")
                
                # Split the folder name into components
                ploidy=$(echo $folder_name | cut -d'_' -f1)
                purity=$(echo $folder_name | cut -d'_' -f2)
                confidence=$(echo $folder_name | cut -d'_' -f3)
                
                # Append to a temporary file
                echo -e "$folder_name\t$ploidy\t$purity\t$confidence"
            done | sort -t$'\t' -k4,4rn > temp.tsv

            # Combine header and sorted content
            (head -n 1 folder_numbers.tsv; cat temp.tsv) > ../purity_ploidy.tsv
            rm temp.tsv folder_numbers.tsv

            cd ..

            # Process Wakhan outputs - extract VCF files from the best solution
            echo "Processing Wakhan outputs..."
            
            # Find the repository name for solution_rank 1 in solutions_ranks.tsv
            if [ -f "${tumor_sample_name}_wakhan/solutions_ranks.tsv" ]; then
              BEST_SOLUTION=$(head -n 2 "${tumor_sample_name}_wakhan/solutions_ranks.tsv" | tail -n 1 | cut -f1)
              echo "Best solution repository: $BEST_SOLUTION"
              
              # Check if the best solution directory exists
              if [ -d "${tumor_sample_name}_wakhan/${BEST_SOLUTION}" ]; then
                BEST_SOLUTION_DIR="${tumor_sample_name}_wakhan/${BEST_SOLUTION}"
                
                # Check if vcf_output subdirectory exists
                if [ -d "${BEST_SOLUTION_DIR}/vcf_output" ]; then
                  echo "Processing VCF files from ${BEST_SOLUTION_DIR}/vcf_output"
                  
                  # Look for the specific VCF files
                  CNA_INTEGERS_VCF=""
                  CNA_SUBCLONALS_VCF=""
                  
                  # Find CNA integers VCF (usually named something like cna_integers.vcf)
                  for vcf_file in "${BEST_SOLUTION_DIR}/vcf_output"/*cna_integers*.vcf; do
                    if [ -f "$vcf_file" ]; then
                      CNA_INTEGERS_VCF="$vcf_file"
                      break
                    fi
                  done
                  
                  # Find CNA subclonals VCF (usually named something like cna_subclonals.vcf)
                  for vcf_file in "${BEST_SOLUTION_DIR}/vcf_output"/*cna_subclonals*.vcf; do
                    if [ -f "$vcf_file" ]; then
                      CNA_SUBCLONALS_VCF="$vcf_file"
                      break
                    fi
                  done
                  
                  # Process CNA integers VCF
                  if [ -n "$CNA_INTEGERS_VCF" ] && [ -f "$CNA_INTEGERS_VCF" ]; then
                    echo "Found CNA integers VCF: $(basename "$CNA_INTEGERS_VCF")"
                    
                    # Copy and rename the VCF file
                    cp "$CNA_INTEGERS_VCF" "${tumor_sample_name}.wakhan_cna_integers.vcf"
                    
                    # Compress the VCF file
                    bgzip "${tumor_sample_name}.wakhan_cna_integers.vcf"
                    
                    # Create TBI index
                    tabix -f -p vcf "${tumor_sample_name}.wakhan_cna_integers.vcf.gz" || { echo "Warning: Failed to index VCF file"; if [ ! -f "${tumor_sample_name}.wakhan_cna_integers.vcf.gz.tbi" ]; then echo "Index file does not exist"; else echo "Index file exists, continuing..."; fi; }
                    
                    echo "Created: ${tumor_sample_name}.wakhan_cna_integers.vcf.gz with index"
                  else
                    echo "Warning: CNA integers VCF not found in ${BEST_SOLUTION_DIR}/vcf_output"
                  fi
                  
                  # Process CNA subclonals VCF
                  if [ -n "$CNA_SUBCLONALS_VCF" ] && [ -f "$CNA_SUBCLONALS_VCF" ]; then
                    echo "Found CNA subclonals VCF: $(basename "$CNA_SUBCLONALS_VCF")"
                    
                    # Copy and rename the VCF file
                    cp "$CNA_SUBCLONALS_VCF" "${tumor_sample_name}.wakhan_cna_subclonals.vcf"
                    
                    # Compress the VCF file
                    bgzip "${tumor_sample_name}.wakhan_cna_subclonals.vcf"
                    
                    # Create TBI index
                    tabix -f -p vcf "${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz" || { echo "Warning: Failed to index VCF file"; if [ ! -f "${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz.tbi" ]; then echo "Index file does not exist"; else echo "Index file exists, continuing..."; fi; }
                    
                    echo "Created: ${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz with index"
                  else
                    echo "Warning: CNA subclonals VCF not found in ${BEST_SOLUTION_DIR}/vcf_output"
                  fi
                  
                else
                  echo "Warning: vcf_output directory not found in ${BEST_SOLUTION_DIR}"
                fi
              else
                echo "Warning: Best solution directory ${tumor_sample_name}_wakhan/${BEST_SOLUTION} not found"
              fi
            else
              echo "Warning: solutions_ranks.tsv not found in ${tumor_sample_name}_wakhan"
            fi
            
            # Clean up the temporary Wakhan directory
            rm -rf ${tumor_sample_name}_wakhan

            # Post-execution logging for Wakhan
            WAKHAN_END_TIME=$(date +%s)
            WAKHAN_DURATION=$((WAKHAN_END_TIME - WAKHAN_START_TIME))
            WAKHAN_DURATION_HOUR=$((WAKHAN_DURATION / 3600))
            WAKHAN_DURATION_MIN=$(((WAKHAN_DURATION % 3600) / 60))
            WAKHAN_DURATION_SEC=$((WAKHAN_DURATION % 60))
            
            echo "================================================"
            echo "‚úÖ WAKHAN ANALYSIS COMPLETED SUCCESSFULLY"
            echo "================================================"
            echo "‚è±Ô∏è  Execution Time: ${WAKHAN_DURATION_HOUR}h ${WAKHAN_DURATION_MIN}m ${WAKHAN_DURATION_SEC}s"
            
            # Calculate total output size
            WAKHAN_TOTAL_SIZE=0
            if [ -f "${tumor_sample_name}.wakhan_cna_integers.vcf.gz" ]; then
              WAKHAN_TOTAL_SIZE=$((WAKHAN_TOTAL_SIZE + $(stat -c%s "${tumor_sample_name}.wakhan_cna_integers.vcf.gz" 2>/dev/null || echo "0")))
            fi
            if [ -f "${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz" ]; then
              WAKHAN_TOTAL_SIZE=$((WAKHAN_TOTAL_SIZE + $(stat -c%s "${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz" 2>/dev/null || echo "0")))
            fi
            
            # Format total size
            if [ $WAKHAN_TOTAL_SIZE -ge 1073741824 ]; then
              WAKHAN_TOTAL_GB=$((WAKHAN_TOTAL_SIZE / 1024 / 1024 / 1024))
              WAKHAN_TOTAL_MB=$(((WAKHAN_TOTAL_SIZE % (1024 * 1024 * 1024)) / 1024 / 1024))
              WAKHAN_TOTAL_DECIMAL=$((WAKHAN_TOTAL_MB * 100 / 1024))
              WAKHAN_TOTAL_FORMATTED="${WAKHAN_TOTAL_GB}.${WAKHAN_TOTAL_DECIMAL} GB"
            elif [ $WAKHAN_TOTAL_SIZE -ge 1048576 ]; then
              WAKHAN_TOTAL_MB=$((WAKHAN_TOTAL_SIZE / 1024 / 1024))
              WAKHAN_TOTAL_KB=$(((WAKHAN_TOTAL_SIZE % (1024 * 1024)) / 1024))
              WAKHAN_TOTAL_DECIMAL=$((WAKHAN_TOTAL_KB * 100 / 1024))
              WAKHAN_TOTAL_FORMATTED="${WAKHAN_TOTAL_MB}.${WAKHAN_TOTAL_DECIMAL} MB"
            else
              WAKHAN_TOTAL_FORMATTED="${WAKHAN_TOTAL_SIZE} bytes"
            fi
            
            echo "üìÅ **Total Output Size: $WAKHAN_TOTAL_FORMATTED**"
            echo "üíæ **Remaining Disk Space: $(df -h /scratch | tail -n 1 | awk '{print $4}')**"
            echo "üìÅ Output Files:"
            
            # Check for Wakhan output files and report their sizes
            if [ -f "${tumor_sample_name}.wakhan_cna_integers.vcf.gz" ]; then
              echo "  - CNA Integers VCF: ${tumor_sample_name}.wakhan_cna_integers.vcf.gz ($(format_file_size "${tumor_sample_name}.wakhan_cna_integers.vcf.gz"))"
            fi
            if [ -f "${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz" ]; then
              echo "  - CNA Subclonals VCF: ${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz ($(format_file_size "${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz"))"
            fi
            echo "================================================"
            
            # Copy Wakhan outputs immediately after completion
            echo "Copying Wakhan outputs..."
            WAKHAN_OUTPUT_FILES=()
            if [ -f "${tumor_sample_name}.wakhan_cna_integers.vcf.gz" ]; then
              WAKHAN_OUTPUT_FILES+=("${tumor_sample_name}.wakhan_cna_integers.vcf.gz")
            fi
            if [ -f "${tumor_sample_name}.wakhan_cna_integers.vcf.gz.tbi" ]; then
              WAKHAN_OUTPUT_FILES+=("${tumor_sample_name}.wakhan_cna_integers.vcf.gz.tbi")
            fi
            if [ -f "${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz" ]; then
              WAKHAN_OUTPUT_FILES+=("${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz")
            fi
            if [ -f "${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz.tbi" ]; then
              WAKHAN_OUTPUT_FILES+=("${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz.tbi")
            fi
            if [ ${#WAKHAN_OUTPUT_FILES[@]} -gt 0 ]; then
              copy_with_progress "$output_folder" "${WAKHAN_OUTPUT_FILES[@]}"
            fi

            # Update vspipeline_inputs.json with Wakhan VCF files
            echo "Updating vspipeline_inputs.json for Wakhan outputs..."
            if ! command -v python3 &> /dev/null; then
              echo "Warning: python3 not available, skipping vspipeline_inputs.json update"
            else
              # Add Wakhan CNA integers VCF to bnd
              WAKHAN_CNA_INTEGERS_VCF="${output_folder}/${tumor_sample_name}.wakhan_cna_integers.vcf.gz"
              if [ -f "$WAKHAN_CNA_INTEGERS_VCF" ]; then
                RELATIVE_PATH="${WAKHAN_CNA_INTEGERS_VCF#${WORKSPACE_DIR}/}"
                python3 "${TASK_DIR}/vspipeline-resources/vspipeline_utilities.py" update-vspipeline-json \
                  --input_dir "$output_folder" \
                  --sample "$tumor_sample_name" \
                  --file "$RELATIVE_PATH" \
                  --file_type bnd \
                  --task_name wakhan \
                  --scratch_dir /scratch || \
                  { echo "Warning: Failed to update vspipeline_inputs.json for Wakhan CNA integers, continuing..."; }
              fi
              
              # Add Wakhan CNA subclonals VCF to bnd
              WAKHAN_CNA_SUBCLONALS_VCF="${output_folder}/${tumor_sample_name}.wakhan_cna_subclonals.vcf.gz"
              if [ -f "$WAKHAN_CNA_SUBCLONALS_VCF" ]; then
                RELATIVE_PATH="${WAKHAN_CNA_SUBCLONALS_VCF#${WORKSPACE_DIR}/}"
                python3 "${TASK_DIR}/vspipeline-resources/vspipeline_utilities.py" update-vspipeline-json \
                  --input_dir "$output_folder" \
                  --sample "$tumor_sample_name" \
                  --file "$RELATIVE_PATH" \
                  --file_type bnd \
                  --task_name wakhan \
                  --scratch_dir /scratch || \
                  { echo "Warning: Failed to update vspipeline_inputs.json for Wakhan CNA subclonals, continuing..."; }
              fi
            fi
          else
            echo "‚ö†Ô∏è  Skipping Wakhan output processing due to previous failure."
            # Clean up any partial Wakhan output directory if it exists
            if [ -d "${tumor_sample_name}_wakhan" ]; then
              echo "Cleaning up partial Wakhan output directory..."
              rm -rf ${tumor_sample_name}_wakhan
            fi
            echo "Continuing with Chord HRD and CNVKit steps..."
          fi
        fi
       
        # Chord HRD:
        # - DeepSomatic VCF
        # - Severus SV VCF

        # Check if Chord HRD outputs already exist
        echo "Checking if Chord HRD outputs already exist..."
        CHORD_LOG_FILES="${output_folder}/chord_hrd.log"
        CHORD_PREDICTION_FILES="${output_folder}/${tumor_sample_name}_chord_prediction.txt"
        CHORD_SIGNATURE_FILES="${output_folder}/${tumor_sample_name}_chord_signatures.txt"
        
        if [ -f "$CHORD_LOG_FILES" ] && [ -f "$CHORD_PREDICTION_FILES" ] && [ -f "$CHORD_SIGNATURE_FILES" ]; then
          echo "Chord HRD outputs already exist. Skipping Chord HRD step."
          echo "  - HRD Log: $(basename "$CHORD_LOG_FILES") ($(format_file_size "$CHORD_LOG_FILES"))"
          echo "  - HRD Prediction: $(basename "$CHORD_PREDICTION_FILES") ($(format_file_size "$CHORD_PREDICTION_FILES"))"
          echo "  - HRD Signature: $(basename "$CHORD_SIGNATURE_FILES") ($(format_file_size "$CHORD_SIGNATURE_FILES"))"
          
          # Set variables to simulate successful completion for downstream steps
          CHORD_HRD_OUTPUT='{"outputs":{"chord_hrd.chord_log":"'$CHORD_LOG_FILES'","chord_hrd.chord_prediction":"'$CHORD_PREDICTION_FILES'","chord_hrd.chord_signature":"'$CHORD_SIGNATURE_FILES'"}}'
        else
          echo "Chord HRD outputs missing. Proceeding with Chord HRD analysis..."

          

          # Pre-execution logging for Chord HRD
          echo "================================================"
          echo "üöÄ STARTING CHORD HRD ANALYSIS"
          echo "================================================"
          echo "üìÖ Server Time: $(date)"
          echo "üìÅ Input Files:"
          echo "  - DeepSomatic VCF: $(basename "$LOCAL_TUMOR_SOMATIC_VCF") ($(format_file_size "$LOCAL_TUMOR_SOMATIC_VCF"))"
          echo "  - Severus SV VCF: $(basename "$SEVERUS_SOMATIC_VCF") ($(format_file_size "$SEVERUS_SOMATIC_VCF"))"
          echo "================================================"
          
          # Record start time
          CHORD_START_TIME=$(date +%s)

          # Generate Chord HRD input JSON
          jq -n \
            --arg pname "$tumor_sample_name" \
            --arg deepsomatic_vcf "$LOCAL_TUMOR_SOMATIC_VCF" \
            --arg severus_sv_vcf "$SEVERUS_SOMATIC_VCF" \
            '{
              "chord_hrd.pname": $pname,
              "chord_hrd.small_variant_vcf": $deepsomatic_vcf,
              "chord_hrd.sv_vcf": $severus_sv_vcf
            }' > /scratch/chord_hrd_inputs.json

          # Run Chord HRD
          echo "Running Chord HRD..."
          set +e
          CHORD_HRD_OUTPUT=$(miniwdl run \
            "${TASK_DIR}/HiFi-somatic-WDL-0.9.2/tasks/annotation.wdl" \
            --task chord_hrd \
            --dir /scratch \
            --runtime-cpu-max=$AGENT_CPU_CORES \
            --runtime-memory-max=${AGENT_MEMORY_GB}G \
            --no-cache \
            -i /scratch/chord_hrd_inputs.json 2>/dev/null)
          CHORD_HRD_OUTPUT_EXIT_CODE=$?
          if [ $CHORD_HRD_OUTPUT_EXIT_CODE -ne 0 ]; then
            handle_miniwdl_failure $CHORD_HRD_OUTPUT_EXIT_CODE
          fi
          
          # Post-execution logging for Chord HRD
          CHORD_END_TIME=$(date +%s)
          CHORD_DURATION=$((CHORD_END_TIME - CHORD_START_TIME))
          CHORD_DURATION_HOUR=$((CHORD_DURATION / 3600))
          CHORD_DURATION_MIN=$(((CHORD_DURATION % 3600) / 60))
          CHORD_DURATION_SEC=$((CHORD_DURATION % 60))
          
          echo "================================================"
          echo "‚úÖ CHORD HRD ANALYSIS COMPLETED SUCCESSFULLY"
          echo "================================================"
          echo "‚è±Ô∏è  Execution Time: ${CHORD_DURATION_HOUR}h ${CHORD_DURATION_MIN}m ${CHORD_DURATION_SEC}s"
          
          # Extract output file paths from CHORD_HRD_OUTPUT
          CHORD_HRD_LOG=$(echo "$CHORD_HRD_OUTPUT" | jq -r '.outputs."chord_hrd.chord_log"')
          CHORD_HRD_PREDICTION=$(echo "$CHORD_HRD_OUTPUT" | jq -r '.outputs."chord_hrd.chord_prediction"')
          CHORD_HRD_SIGNATURE=$(echo "$CHORD_HRD_OUTPUT" | jq -r '.outputs."chord_hrd.chord_signature"')
          
          # Calculate total output size
          CHORD_TOTAL_SIZE=0
          if [ -f "$CHORD_HRD_LOG" ]; then
            CHORD_TOTAL_SIZE=$((CHORD_TOTAL_SIZE + $(stat -c%s "$CHORD_HRD_LOG" 2>/dev/null || echo "0")))
          fi
          if [ -f "$CHORD_HRD_PREDICTION" ]; then
            CHORD_TOTAL_SIZE=$((CHORD_TOTAL_SIZE + $(stat -c%s "$CHORD_HRD_PREDICTION" 2>/dev/null || echo "0")))
          fi
          if [ -f "$CHORD_HRD_SIGNATURE" ]; then
            CHORD_TOTAL_SIZE=$((CHORD_TOTAL_SIZE + $(stat -c%s "$CHORD_HRD_SIGNATURE" 2>/dev/null || echo "0")))
          fi
          
          # Format total size
          if [ $CHORD_TOTAL_SIZE -ge 1073741824 ]; then
            CHORD_TOTAL_GB=$((CHORD_TOTAL_SIZE / 1024 / 1024 / 1024))
            CHORD_TOTAL_MB=$(((CHORD_TOTAL_SIZE % (1024 * 1024 * 1024)) / 1024 / 1024))
            CHORD_TOTAL_DECIMAL=$((CHORD_TOTAL_MB * 100 / 1024))
            CHORD_TOTAL_FORMATTED="${CHORD_TOTAL_GB}.${CHORD_TOTAL_DECIMAL} GB"
          elif [ $CHORD_TOTAL_SIZE -ge 1048576 ]; then
            CHORD_TOTAL_MB=$((CHORD_TOTAL_SIZE / 1024 / 1024))
            CHORD_TOTAL_KB=$(((CHORD_TOTAL_SIZE % (1024 * 1024)) / 1024))
            CHORD_TOTAL_DECIMAL=$((CHORD_TOTAL_KB * 100 / 1024))
            CHORD_TOTAL_FORMATTED="${CHORD_TOTAL_MB}.${CHORD_TOTAL_DECIMAL} MB"
          else
            CHORD_TOTAL_FORMATTED="${CHORD_TOTAL_SIZE} bytes"
          fi
          
          echo "üìÅ **Total Output Size: $CHORD_TOTAL_FORMATTED**"
          echo "üíæ **Remaining Disk Space: $(df -h /scratch | tail -n 1 | awk '{print $4}')**"
          echo "üìÅ Output Files:"
          
          if [ -f "$CHORD_HRD_LOG" ]; then
            echo "  - HRD Log: $(basename "$CHORD_HRD_LOG") ($(format_file_size "$CHORD_HRD_LOG"))"
          fi
          if [ -f "$CHORD_HRD_PREDICTION" ]; then
            echo "  - HRD Prediction: $(basename "$CHORD_HRD_PREDICTION") ($(format_file_size "$CHORD_HRD_PREDICTION"))"
          fi
          if [ -f "$CHORD_HRD_SIGNATURE" ]; then
            echo "  - HRD Signature: $(basename "$CHORD_HRD_SIGNATURE") ($(format_file_size "$CHORD_HRD_SIGNATURE"))"
          fi
          echo "================================================"
          
          # Copy Chord HRD outputs immediately after completion
          echo "Copying Chord HRD outputs..."
          CHORD_OUTPUT_FILES=()
          if [ -n "$CHORD_HRD_LOG" ] && [ "$CHORD_HRD_LOG" != "null" ] && [ -f "$CHORD_HRD_LOG" ]; then
            CHORD_OUTPUT_FILES+=("$CHORD_HRD_LOG")
          fi
          if [ -n "$CHORD_HRD_PREDICTION" ] && [ "$CHORD_HRD_PREDICTION" != "null" ] && [ -f "$CHORD_HRD_PREDICTION" ]; then
            CHORD_OUTPUT_FILES+=("$CHORD_HRD_PREDICTION")
          fi
          if [ -n "$CHORD_HRD_SIGNATURE" ] && [ "$CHORD_HRD_SIGNATURE" != "null" ] && [ -f "$CHORD_HRD_SIGNATURE" ]; then
            CHORD_OUTPUT_FILES+=("$CHORD_HRD_SIGNATURE")
          fi
          if [ ${#CHORD_OUTPUT_FILES[@]} -gt 0 ]; then
            copy_with_progress "$output_folder" "${CHORD_OUTPUT_FILES[@]}"
          fi
          
          echo "Chord HRD output: $CHORD_HRD_OUTPUT"
          echo "Chord HRD completed successfully"
        fi

        # CNVKit:
        # - Tumor BAM
        # - Tumor BAM index
        # - Normal BAM
        # - Normal BAM index
        # - Reference FASTA
        # - Reference FASTA index
        # - Reference FLAT

        # Check if CNVKit outputs already exist
        echo "Checking if CNVKit outputs already exist..."
        CNVKIT_CNS_FILE="${output_folder}/${tumor_sample_name}.cnvkit.call.cns"
        CNVKIT_DIAGRAM_FILE="${output_folder}/${tumor_sample_name}.cnvkit-diagram.pdf"
        CNVKIT_SCATTER_FILE="${output_folder}/${tumor_sample_name}.cnvkit-scatter.png"
        
        if [ -f "$CNVKIT_CNS_FILE" ] && [ -f "$CNVKIT_DIAGRAM_FILE" ] && [ -f "$CNVKIT_SCATTER_FILE" ]; then
          echo "CNVKit outputs already exist. Skipping CNVKit step."
          echo "  - CNS File: $(basename "$CNVKIT_CNS_FILE") ($(format_file_size "$CNVKIT_CNS_FILE"))"
          echo "  - Diagram PDF: $(basename "$CNVKIT_DIAGRAM_FILE") ($(format_file_size "$CNVKIT_DIAGRAM_FILE"))"
          echo "  - Scatter PNG: $(basename "$CNVKIT_SCATTER_FILE") ($(format_file_size "$CNVKIT_SCATTER_FILE"))"
          
          # Set variables to simulate successful completion for downstream steps
          CNVKIT_OUTPUT='{"outputs":{"cnvkit_tumor.cnr":"'$CNVKIT_CNS_FILE'","cnvkit_tumor.cns":"'$CNVKIT_CNS_FILE'","cnvkit_tumor.calls":"'$CNVKIT_CNS_FILE'"}}'
        else
          echo "CNVKit outputs missing. Proceeding with CNVKit analysis..."

          # Pre-execution logging for CNVKit
          echo "================================================"
          echo "üöÄ STARTING CNVKIT ANALYSIS"
          echo "================================================"
          echo "üìÖ Server Time: $(date)"
          echo "üìÅ Input Files:"
          echo "  - Tumor BAM: $(basename "$LOCAL_TUMOR_BAM") ($(format_file_size "$LOCAL_TUMOR_BAM"))"
          echo "  - Tumor BAM Index: $(basename "$LOCAL_TUMOR_BAM_INDEX") ($(format_file_size "$LOCAL_TUMOR_BAM_INDEX"))"
          echo "  - Normal BAM: $(basename "$LOCAL_NORMAL_BAM") ($(format_file_size "$LOCAL_NORMAL_BAM"))"
          echo "  - Normal BAM Index: $(basename "$LOCAL_NORMAL_BAM_INDEX") ($(format_file_size "$LOCAL_NORMAL_BAM_INDEX"))"
          echo "  - Reference FASTA: $(basename "$LOCAL_REF_FASTA") ($(format_file_size "$LOCAL_REF_FASTA"))"
          echo "  - Reference FASTA Index: $(basename "$LOCAL_REF_INDEX") ($(format_file_size "$LOCAL_REF_INDEX"))"
          echo "  - Reference FLAT: $(basename "$LOCAL_REF_FLAT") ($(format_file_size "$LOCAL_REF_FLAT"))"
          echo "================================================"
          
          # Record start time
          CNVKIT_START_TIME=$(date +%s)

          echo "Starting CNVKit..."

          # Generate CNVKit input JSON
          jq -n \
            --arg pname "$tumor_sample_name" \
            --arg tumor_bam "$LOCAL_TUMOR_BAM" \
            --arg tumor_bam_index "$LOCAL_TUMOR_BAM_INDEX" \
            --arg normal_bam "$LOCAL_NORMAL_BAM" \
            --arg normal_bam_index "$LOCAL_NORMAL_BAM_INDEX" \
            --arg ref_fasta "$LOCAL_REF_FASTA" \
            --arg ref_fasta_index "$LOCAL_REF_INDEX" \
            --arg refFlat "$LOCAL_REF_FLAT" \
            --argjson threads "$AGENT_CPU_CORES" \
            '{
              "cnvkit_tumor.pname": $pname,
              "cnvkit_tumor.tumor_bam": $tumor_bam,
              "cnvkit_tumor.tumor_bam_index": $tumor_bam_index,
              "cnvkit_tumor.normal_bam": $normal_bam,
              "cnvkit_tumor.normal_bam_index": $normal_bam_index,
              "cnvkit_tumor.ref_fasta": $ref_fasta,
              "cnvkit_tumor.ref_fasta_index": $ref_fasta_index,
              "cnvkit_tumor.refFlat": $refFlat,
              "cnvkit_tumor.threads": $threads
            }' > /scratch/cnvkit_inputs.json

          # Run CNVKit
          echo "Running CNVKit..."
          set +e
          CNVKIT_OUTPUT=$(miniwdl run \
            "${TASK_DIR}/HiFi-somatic-WDL-0.9.2/tasks/cnvkit.wdl" \
            --task cnvkit_tumor \
            --dir /scratch \
            --runtime-cpu-max=$AGENT_CPU_CORES \
            --runtime-memory-max=${AGENT_MEMORY_GB}G \
            --no-cache \
            -i /scratch/cnvkit_inputs.json 2>/dev/null)
          CNVKIT_OUTPUT_EXIT_CODE=$?
          if [ $CNVKIT_OUTPUT_EXIT_CODE -ne 0 ]; then
            handle_miniwdl_failure $CNVKIT_OUTPUT_EXIT_CODE
          fi
          
          # Post-execution logging for CNVKit
          CNVKIT_END_TIME=$(date +%s)
          CNVKIT_DURATION=$((CNVKIT_END_TIME - CNVKIT_START_TIME))
          CNVKIT_DURATION_HOUR=$((CNVKIT_DURATION / 3600))
          CNVKIT_DURATION_MIN=$(((CNVKIT_DURATION % 3600) / 60))
          CNVKIT_DURATION_SEC=$((CNVKIT_DURATION % 60))
          
          echo "================================================"
          echo "‚úÖ CNVKIT ANALYSIS COMPLETED SUCCESSFULLY"
          echo "================================================"
          echo "‚è±Ô∏è  Execution Time: ${CNVKIT_DURATION_HOUR}h ${CNVKIT_DURATION_MIN}m ${CNVKIT_DURATION_SEC}s"
          
          # Extract output file paths from CNVKIT_OUTPUT
          CNVKIT_CNR=$(echo "$CNVKIT_OUTPUT" | jq -r '.outputs."cnvkit_tumor.cnr"')
          CNVKIT_CNS=$(echo "$CNVKIT_OUTPUT" | jq -r '.outputs."cnvkit_tumor.cns"')
          CNVKIT_CALLS=$(echo "$CNVKIT_OUTPUT" | jq -r '.outputs."cnvkit_tumor.calls"')
          
          # Calculate total output size
          CNVKIT_TOTAL_SIZE=0
          if [ -f "$CNVKIT_CNR" ]; then
            CNVKIT_TOTAL_SIZE=$((CNVKIT_TOTAL_SIZE + $(stat -c%s "$CNVKIT_CNR" 2>/dev/null || echo "0")))
          fi
          if [ -f "$CNVKIT_CNS" ]; then
            CNVKIT_TOTAL_SIZE=$((CNVKIT_TOTAL_SIZE + $(stat -c%s "$CNVKIT_CNS" 2>/dev/null || echo "0")))
          fi
          if [ -f "$CNVKIT_CALLS" ]; then
            CNVKIT_TOTAL_SIZE=$((CNVKIT_TOTAL_SIZE + $(stat -c%s "$CNVKIT_CALLS" 2>/dev/null || echo "0")))
          fi
          
          # Format total size
          if [ $CNVKIT_TOTAL_SIZE -ge 1073741824 ]; then
            CNVKIT_TOTAL_GB=$((CNVKIT_TOTAL_SIZE / 1024 / 1024 / 1024))
            CNVKIT_TOTAL_MB=$(((CNVKIT_TOTAL_SIZE % (1024 * 1024 * 1024)) / 1024 / 1024))
            CNVKIT_TOTAL_DECIMAL=$((CNVKIT_TOTAL_MB * 100 / 1024))
            CNVKIT_TOTAL_FORMATTED="${CNVKIT_TOTAL_GB}.${CNVKIT_TOTAL_DECIMAL} GB"
          elif [ $CNVKIT_TOTAL_SIZE -ge 1048576 ]; then
            CNVKIT_TOTAL_MB=$((CNVKIT_TOTAL_SIZE / 1024 / 1024))
            CNVKIT_TOTAL_KB=$(((CNVKIT_TOTAL_SIZE % (1024 * 1024)) / 1024))
            CNVKIT_TOTAL_DECIMAL=$((CNVKIT_TOTAL_KB * 100 / 1024))
            CNVKIT_TOTAL_FORMATTED="${CNVKIT_TOTAL_MB}.${CNVKIT_TOTAL_DECIMAL} MB"
          else
            CNVKIT_TOTAL_FORMATTED="${CNVKIT_TOTAL_SIZE} bytes"
          fi
          
          echo "üìÅ **Total Output Size: $CNVKIT_TOTAL_FORMATTED**"
          echo "üíæ **Remaining Disk Space: $(df -h /scratch | tail -n 1 | awk '{print $4}')**"
          echo "üìÅ Output Files:"
          
          if [ -f "$CNVKIT_CNR" ]; then
            echo "  - CNR File: $(basename "$CNVKIT_CNR") ($(format_file_size "$CNVKIT_CNR"))"
          fi
          if [ -f "$CNVKIT_CNS" ]; then
            echo "  - CNS File: $(basename "$CNVKIT_CNS") ($(format_file_size "$CNVKIT_CNS"))"
          fi
          if [ -f "$CNVKIT_CALLS" ]; then
            echo "  - Calls File: $(basename "$CNVKIT_CALLS") ($(format_file_size "$CNVKIT_CALLS"))"
          fi
          echo "================================================"
          
          # Copy CNVKit outputs immediately after completion
          echo "Copying CNVKit outputs..."
          CNVKIT_FILES=$(echo "$CNVKIT_OUTPUT" | jq -r '.outputs["cnvkit_tumor.cnvkit_output"] | join(" ")')
          if [ -n "$CNVKIT_FILES" ] && [ "$CNVKIT_FILES" != "null" ]; then
            CNVKIT_OUTPUT_FILES=()
            CNVKIT_CNS_FILE=""
            for file in $CNVKIT_FILES; do
              if [ -f "$file" ]; then
                # Extract filename and check if it's one of our target files
                filename=$(basename "$file")
                if [[ "$filename" == *".call.cns" ]] || [[ "$filename" == *"-diagram.pdf" ]] || [[ "$filename" == *"-scatter.png" ]]; then
                  # Rename the file to replace anything between sample name and suffix with `cnvkit`
                  # Handle different file patterns: .call.cns, -diagram.pdf, -scatter.png
                  if [[ "$filename" == *".call.cns" ]]; then
                    new_file=$(echo "$file" | sed "s/${tumor_sample_name}\.[^.]*/${tumor_sample_name}.cnvkit/")
                    CNVKIT_CNS_FILE="$new_file"
                  elif [[ "$filename" == *"-diagram.pdf" ]]; then
                    new_file=$(echo "$file" | sed "s/${tumor_sample_name}[^-]*-/${tumor_sample_name}.cnvkit-/")
                  elif [[ "$filename" == *"-scatter.png" ]]; then
                    new_file=$(echo "$file" | sed "s/${tumor_sample_name}[^-]*-/${tumor_sample_name}.cnvkit-/")
                  fi
                  mv "$file" "$new_file"
                  echo "Renamed $file to $new_file"
                  CNVKIT_OUTPUT_FILES+=("$new_file")
                else
                  echo "Skipping intermediate file: $filename"
                fi
              fi
            done
            
            # Update CNVKit CNS file with CNV State field using vspipeline_utilities.py
            if [ -n "$CNVKIT_CNS_FILE" ] && [ -f "$CNVKIT_CNS_FILE" ]; then
              echo "Updating CNVKit CNV file with CNV State field..."
              python3 "${TASK_DIR}/vspipeline-resources/vspipeline_utilities.py" update-cnv-file \
                --input "$CNVKIT_CNS_FILE" \
                --output "${CNVKIT_CNS_FILE}.tmp"
              
              # Replace original with updated file
              mv "${CNVKIT_CNS_FILE}.tmp" "$CNVKIT_CNS_FILE"
              echo "CNVKit CNV file updated with CNV State field"
            fi
            
            if [ ${#CNVKIT_OUTPUT_FILES[@]} -gt 0 ]; then
              copy_with_progress "$output_folder" "${CNVKIT_OUTPUT_FILES[@]}"
            fi

            # Update vspipeline_inputs.json with CNVKit CNV file
            echo "Updating vspipeline_inputs.json for CNVKit outputs..."
            if ! command -v python3 &> /dev/null; then
              echo "Warning: python3 not available, skipping vspipeline_inputs.json update"
            else
              # Add CNVKit CNS file to cnv
              CNVKIT_CNS_FILE="${output_folder}/${tumor_sample_name}.cnvkit.call.cns"
              if [ -f "$CNVKIT_CNS_FILE" ]; then
                RELATIVE_PATH="${CNVKIT_CNS_FILE#${WORKSPACE_DIR}/}"
                python3 "${TASK_DIR}/vspipeline-resources/vspipeline_utilities.py" update-vspipeline-json \
                  --input_dir "$output_folder" \
                  --sample "$tumor_sample_name" \
                  --file "$RELATIVE_PATH" \
                  --file_type cnv \
                  --task_name cnvkit \
                  --scratch_dir /scratch || \
                  { echo "Warning: Failed to update vspipeline_inputs.json for CNVKit, continuing..."; }
              fi
            fi
          else
            echo "Warning: CNVKit output files not found in results"
          fi
          
          echo "CNVKit output: $CNVKIT_OUTPUT"
        fi

        echo "Structural variant analysis completed successfully"
        echo "All output files have been copied to: $output_folder"
